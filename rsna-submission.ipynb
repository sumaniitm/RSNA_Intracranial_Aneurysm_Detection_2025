{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":99552,"databundleVersionId":13851420,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":8236972,"sourceType":"datasetVersion","datasetId":4885707},{"sourceId":13213620,"sourceType":"datasetVersion","datasetId":8127880},{"sourceId":13227935,"sourceType":"datasetVersion","datasetId":8384705},{"sourceId":594988,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":445390,"modelId":461858}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install duckdb --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\n!pip install numpy --no-index --find-links=/kaggle/input/suman-dicom-tpu-supporting-combo/dicom_tpu_supporting_combo/kaggle/working/mysitepackages/pylibjpeg_libjpeg/numpy-2.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n\n!pip install pylibjpeg-libjpeg==2.2.0 --no-index --find-links=/kaggle/input/suman-dicom-tpu-supporting-combo/dicom_tpu_supporting_combo/kaggle/working/mysitepackages/pylibjpeg_libjpeg\n!pip install pylibjpeg-openjpeg==2.3.0 --no-index --find-links=/kaggle/input/suman-dicom-tpu-supporting-combo/dicom_tpu_supporting_combo/kaggle/working/mysitepackages/pylibjpeg_openjpeg\n\n!pip install python-gdcm --no-index --find-links=/kaggle/input/suman-dicom-tpu-supporting-combo/pydicom_working_combo/kaggle/working/mysitepackages/python_gdcm\n!pip install pylibjpeg --no-index --find-links=/kaggle/input/suman-dicom-tpu-supporting-combo/pydicom_working_combo/kaggle/working/mysitepackages/pylibjpeg\n\n!pip install polars --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\n!pip install pydicom --no-index --find-links=/kaggle/input/suman-dicom-tpu-supporting-combo/pydicom_working_combo/kaggle/working/mysitepackages/pydicom\n\n!pip install tensorflow-io==0.37.1 --no-index --find-links=/kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow_io\n\n!pip install tensorflow==2.16.1 --no-index --find-links=/kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:34:41.201953Z","iopub.execute_input":"2025-10-11T19:34:41.202411Z","iopub.status.idle":"2025-10-11T19:36:29.752701Z","shell.execute_reply.started":"2025-10-11T19:34:41.202371Z","shell.execute_reply":"2025-10-11T19:36:29.751220Z"}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/suman-dicom-tpu-supporting-combo/dicom_tpu_supporting_combo/kaggle/working/mysitepackages/pylibjpeg_libjpeg/numpy-2.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nLooking in links: /kaggle/input/suman-dicom-tpu-supporting-combo/dicom_tpu_supporting_combo/kaggle/working/mysitepackages/pylibjpeg_libjpeg\nProcessing /kaggle/input/suman-dicom-tpu-supporting-combo/dicom_tpu_supporting_combo/kaggle/working/mysitepackages/pylibjpeg_libjpeg/pylibjpeg_libjpeg-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pylibjpeg-libjpeg==2.2.0) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-libjpeg==2.2.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-libjpeg==2.2.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-libjpeg==2.2.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-libjpeg==2.2.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-libjpeg==2.2.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-libjpeg==2.2.0) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pylibjpeg-libjpeg==2.2.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pylibjpeg-libjpeg==2.2.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pylibjpeg-libjpeg==2.2.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pylibjpeg-libjpeg==2.2.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pylibjpeg-libjpeg==2.2.0) (2024.2.0)\nInstalling collected packages: pylibjpeg-libjpeg\nSuccessfully installed pylibjpeg-libjpeg-2.2.0\nLooking in links: /kaggle/input/suman-dicom-tpu-supporting-combo/dicom_tpu_supporting_combo/kaggle/working/mysitepackages/pylibjpeg_openjpeg\nProcessing /kaggle/input/suman-dicom-tpu-supporting-combo/dicom_tpu_supporting_combo/kaggle/working/mysitepackages/pylibjpeg_openjpeg/pylibjpeg_openjpeg-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pylibjpeg-openjpeg==2.3.0) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-openjpeg==2.3.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-openjpeg==2.3.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-openjpeg==2.3.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-openjpeg==2.3.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-openjpeg==2.3.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg-openjpeg==2.3.0) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pylibjpeg-openjpeg==2.3.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pylibjpeg-openjpeg==2.3.0) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pylibjpeg-openjpeg==2.3.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pylibjpeg-openjpeg==2.3.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pylibjpeg-openjpeg==2.3.0) (2024.2.0)\nInstalling collected packages: pylibjpeg-openjpeg\nSuccessfully installed pylibjpeg-openjpeg-2.3.0\nLooking in links: /kaggle/input/suman-dicom-tpu-supporting-combo/pydicom_working_combo/kaggle/working/mysitepackages/python_gdcm\nProcessing /kaggle/input/suman-dicom-tpu-supporting-combo/pydicom_working_combo/kaggle/working/mysitepackages/python_gdcm/python_gdcm-3.2.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\nInstalling collected packages: python-gdcm\nSuccessfully installed python-gdcm-3.2.2\nLooking in links: /kaggle/input/suman-dicom-tpu-supporting-combo/pydicom_working_combo/kaggle/working/mysitepackages/pylibjpeg\nProcessing /kaggle/input/suman-dicom-tpu-supporting-combo/pydicom_working_combo/kaggle/working/mysitepackages/pylibjpeg/pylibjpeg-2.1.0-py3-none-any.whl\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pylibjpeg) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pylibjpeg) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pylibjpeg) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pylibjpeg) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pylibjpeg) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pylibjpeg) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pylibjpeg) (2024.2.0)\nInstalling collected packages: pylibjpeg\nSuccessfully installed pylibjpeg-2.1.0\nLooking in links: /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\nRequirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\nLooking in links: /kaggle/input/suman-dicom-tpu-supporting-combo/pydicom_working_combo/kaggle/working/mysitepackages/pydicom\nRequirement already satisfied: pydicom in /usr/local/lib/python3.11/dist-packages (3.0.1)\nLooking in links: /kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow_io\nRequirement already satisfied: tensorflow-io==0.37.1 in /usr/local/lib/python3.11/dist-packages (0.37.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-io==0.37.1) (0.37.1)\nLooking in links: /kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow\nProcessing /kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow/tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.14.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (18.1.1)\nProcessing /kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow/ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from tensorflow==2.16.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (2.32.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (4.14.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.73.1)\nProcessing /kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow/tensorboard-2.16.2-py3-none-any.whl (from tensorflow==2.16.1)\nRequirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.8.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.16.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2025.6.15)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.8.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.19.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\nInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.18.0\n    Uninstalling tensorflow-2.18.0:\n      Successfully uninstalled tensorflow-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.16.1 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.16.1 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\"\"\"!pip download python-gdcm --no-deps -d /kaggle/working/mysitepackages/python_gdcm\n!pip download pylibjpeg --no-deps -d /kaggle/working/mysitepackages/pylibjpeg\n!pip download pydicom --no-deps -d /kaggle/working/mysitepackages/pydicom\"\"\"\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"from zipfile import ZipFile\n\ndirName = '/kaggle/working/mysitepackages'\nzipName = 'pydicom_working_combo.zip'\n\n# Create a ZipFile Object\nwith ZipFile(zipName, 'w') as zipObj:\n    # Iterate over all the files in directory\n    for folderName, subfolders, filenames in os.walk(dirName):\n        for filename in filenames:\n            if (filename != zipName):\n                # create complete filepath of file in directory\n                filePath = os.path.join(folderName, filename)\n                # Add file to zip\n                zipObj.write(filePath)\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pydicom\nfrom pydicom import dcmread\nfrom pydicom.dataset import FileDataset, FileMetaDataset\nfrom pydicom.uid import generate_uid, ImplicitVRLittleEndian\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport polars as pl\nimport duckdb as dd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport cv2\nimport pickle\nimport gc\nimport ctypes\nfrom pathlib import Path\nimport logging\nimport json\nimport multiprocessing as mp\nfrom concurrent.futures import ProcessPoolExecutor\nimport datetime\nfrom typing import Tuple, Optional\nimport warnings\nwarnings.filterwarnings('ignore')\nimport shutil\n\n#from sklearn.model_selection import train_test_split\n#from sklearn.preprocessing import LabelEncoder\n#from sklearn.metrics import log_loss\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \nimport tensorflow as tf\nimport tensorflow_io as tfio\nfrom tensorflow import keras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:36:49.150475Z","iopub.execute_input":"2025-10-11T19:36:49.150890Z","iopub.status.idle":"2025-10-11T19:37:02.767177Z","shell.execute_reply.started":"2025-10-11T19:36:49.150853Z","shell.execute_reply":"2025-10-11T19:37:02.766203Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"print(tf.__version__)\nprint(tfio.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:37:05.651511Z","iopub.execute_input":"2025-10-11T19:37:05.652209Z","iopub.status.idle":"2025-10-11T19:37:05.657651Z","shell.execute_reply.started":"2025-10-11T19:37:05.652178Z","shell.execute_reply":"2025-10-11T19:37:05.656614Z"}},"outputs":[{"name":"stdout","text":"2.16.1\n0.37.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from tensorflow.keras.applications import InceptionV3\nfrom tensorflow.keras import layers\n\nWEIGHTS_PATH = \"/kaggle/input/suman-keras-inception-net-v3-weights/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nbias_list = [-9.21101, -7.87573, -7.83279, -9.43417, -9.83967, -8.16937, -9.43417\n             , 6.085, -9.24492, -8.20532, -9.83967, -9.24492, -9.14646, -8.20532]\n\nrsna_input = layers.Input(shape=(128,128,3), name=\"rsna_input\")\nconv_base = InceptionV3(include_top=False, weights=WEIGHTS_PATH, input_tensor=rsna_input, input_shape=(128,128,3))\nconv_base.trainable = False\n\nconv2d_1 = layers.Conv2D(filters=14, data_format=\"channels_last\", kernel_size=(1, 1), use_bias=True\n                         ,bias_initializer=tf.keras.initializers.Constant(np.array(bias_list))\n                         ,  strides=(1, 1), padding=\"valid\", activation=\"relu\")(conv_base.output)\n\nflattened_layer = layers.Flatten()(conv2d_1)\n\nrsna_output = layers.Dense(14, activation=\"softmax\", bias_initializer=tf.keras.initializers.Constant(np.array(bias_list)))(flattened_layer)\nmodel = tf.keras.Model(rsna_input, rsna_output)\n\nmodel.load_weights('/kaggle/input/rsna-aneurysm-cta-base/tensorflow2/inception-v3-transfer-learning/2/keras_inceptionnet_baseline.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:37:09.019298Z","iopub.execute_input":"2025-10-11T19:37:09.020036Z","iopub.status.idle":"2025-10-11T19:37:28.681531Z","shell.execute_reply.started":"2025-10-11T19:37:09.020005Z","shell.execute_reply":"2025-10-11T19:37:28.680641Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\"\"\"def custom_auc_metric():\n        return tf.keras.metrics.AUC(multi_label=True, num_labels=14, from_logits=False\n                                    , label_weights=[1,1,1,1,1,1,1,13,1,1,1,1,1,1])\n\nmodel = keras.models.\\\nload_model(\"/kaggle/input/rsna-aneurysm-cta-base/tensorflow2/inception-v3-transfer-learning/2/keras_inceptionnet_baseline.keras\"\n           , custom_objects={'AUC': custom_auc_metric})\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from multiprocessing import cpu_count\nn_cores = cpu_count()\nprint(f'Number of Logical CPU cores: {n_cores}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:37:42.022585Z","iopub.execute_input":"2025-10-11T19:37:42.022970Z","iopub.status.idle":"2025-10-11T19:37:42.028378Z","shell.execute_reply.started":"2025-10-11T19:37:42.022942Z","shell.execute_reply":"2025-10-11T19:37:42.027355Z"}},"outputs":[{"name":"stdout","text":"Number of Logical CPU cores: 4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"allowed_tags = ['BitsAllocated', 'BitsStored', 'Rows', 'Columns', 'FrameOfReferenceUID', 'HighBit', 'ImageOrientationPatient'\n                , 'ImagePositionPatient', 'InstanceNumber', 'Modality', 'PhotometricInterpretation'\n                , 'PixelRepresentation', 'PixelSpacing', 'PlanarConfiguration', 'RescaleIntercept', 'RescaleSlope'\n                , 'RescaleType', 'SamplesPerPixel', 'SliceThickness', 'SpacingBetweenSlices']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:37:43.904876Z","iopub.execute_input":"2025-10-11T19:37:43.905216Z","iopub.status.idle":"2025-10-11T19:37:43.910738Z","shell.execute_reply.started":"2025-10-11T19:37:43.905194Z","shell.execute_reply":"2025-10-11T19:37:43.909670Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"pos_dict = {0: 'anterior_communicating_artery',\n 1: 'basilar_tip',\n 2: 'left_anterior_cerebral_artery',\n 3: 'left_infraclinoid_internal_carotid_artery',\n 4: 'left_middle_cerebral_artery',\n 5: 'left_posterior_communicating_artery',\n 6: 'left_supraclinoid_internal_carotid_artery',\n 7: 'aneurysm_present',\n 8: 'other_posterior_circulation',\n 9: 'right_anterior_cerebral_artery',\n 10: 'right_infraclinoid_internal_carotid_artery',\n 11: 'right_middle_cerebral_artery',\n 12: 'right_posterior_communicating_artery',\n 13: 'right_supraclinoid_internal_carotid_artery'}\n\nSUBMISSION_COLS = [\n    'SeriesInstanceUID',\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present',\n]\n\nLABEL_COLS = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present',\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:37:45.144433Z","iopub.execute_input":"2025-10-11T19:37:45.144762Z","iopub.status.idle":"2025-10-11T19:37:45.151897Z","shell.execute_reply.started":"2025-10-11T19:37:45.144737Z","shell.execute_reply":"2025-10-11T19:37:45.150949Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"BATCH_SIZE = 8\n\ndef format_column_name(snake_str):\n    \"\"\"Convert snake_case string to Title Case with spaces\"\"\"\n    # Split the string into words and capitalize each word\n    return ' '.join(word.capitalize() for word in snake_str.split('_'))\n\ndef process_mri_t2(image: np.ndarray):\n    \"\"\"\n    Specific preprocessing for T2-weighted MRI\n    - Bias field correction\n    - Intensity normalization\n    \"\"\"\n    # Convert to float32\n    image = image.astype(np.float32)\n    \n    # Apply N4 bias field correction if needed\n    # Note: This would require SimpleITK, commented out for simplicity\n    # image = self._apply_bias_correction(image)\n    \n    # Z-score normalization\n    mean = np.mean(image)\n    std = np.std(image)\n    image = (image - mean) / (std + 1e-10)\n    \n    # Scale to [0,1] range\n    image = (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-10)\n    \n    return image\n\ndef process_mri_t1_post(image: np.ndarray):\n    \"\"\"\n    Specific preprocessing for T1 post-contrast MRI\n    - Enhancement of contrast regions\n    - Intensity standardization\n    \"\"\"\n    image = image.astype(np.float32)\n    \n    # Enhance contrast\n    p2, p98 = np.percentile(image, (2, 98))\n    image = np.clip(image, p2, p98)\n    \n    # Normalize to [0,1]\n    image = (image - p2) / (p98 - p2 + 1e-10)\n    \n    return image\n\ndef process_cta(image: np.ndarray, dcm: pydicom.dataset.FileDataset):\n    \"\"\"\n    Specific preprocessing for CTA\n    - Window/level optimization for vessel visualization\n    - Vessel enhancement\n    \"\"\"\n    # Get window settings (typical for CTA)\n    window_center = 100  # Typical for CTA\n    window_width = 700   # Typical for CTA\n    \n    # Override with DICOM values if available\n    if hasattr(dcm, 'WindowCenter') and hasattr(dcm, 'WindowWidth'):\n        window_center = dcm.WindowCenter\n        window_width = dcm.WindowWidth\n        \n        # Handle multiple window settings\n        if isinstance(window_center, pydicom.multival.MultiValue):\n            window_center = window_center[0]\n        if isinstance(window_width, pydicom.multival.MultiValue):\n            window_width = window_width[0]\n    \n    # Apply window/level\n    min_value = window_center - window_width // 2\n    max_value = window_center + window_width // 2\n    image = np.clip(image, min_value, max_value)\n    \n    # Normalize to [0,1]\n    image = (image - min_value) / (max_value - min_value + 1e-10)\n    \n    return image\n\ndef process_mra(image: np.ndarray):\n    \"\"\"\n    Specific preprocessing for MRA\n    - Maximum intensity projection consideration\n    - Vessel enhancement\n    \"\"\"\n    image = image.astype(np.float32)\n    \n    # Normalize based on tissue characteristics\n    p0, p100 = np.percentile(image, (0, 100))\n    image = (image - p0) / (p100 - p0 + 1e-10)\n    \n    # Optional: Vessel enhancement using Frangi filter\n    # Note: This would require additional dependencies\n    # image = self._apply_vessel_enhancement(image)\n    \n    return image\n\ndef read_and_parse_dicom_files_tensorflow_train(dcm_path, f_coord=None):\n    #print(\"dcm_path - \", dcm_path)\n    \"\"\"raw_image = tf.io.read_file(dcm_path)\n    image = tfio.image.decode_dicom_image(raw_image, scale='auto', on_error='lossy', dtype=tf.float32)\n\n    tag_id = tfio.image.dicom_tags.Modality\n    tag_value = tfio.image.decode_dicom_data(raw_image,tag_id)\n    modality = tag_value.numpy().decode('UTF-8')\"\"\"\n\n    # Read the DICOM file\n    raw_image = dcmread(dcm_path.numpy().decode('utf-8'))\n    \n    # Access the pixel data as a NumPy array\n    image = raw_image.pixel_array\n    modality = raw_image.Modality\n\n    if modality == 'CTA':\n        image = process_cta(image, dcm_path)\n        \n    if modality == 'MRA':\n        image = process_mra(image)\n        \n    if modality == 'MRI T2':\n        image = process_mri_t2(image)\n\n    if modality == 'MRI T1post':\n        image = process_mri_t1_post(image)\n\n    #print(image.shape)\n\n    if np.any(np.isnan(image)):\n        print(f\"Warning: NaN values found in image {dcm_path}\")\n        \n    if np.any(np.isinf(image)):\n        print(f\"Warning: Infinite values found in image {dcm_path}\")\n\n    # this one is for TF DICOM read\n    \"\"\"specific_slice_tensor = tf.slice(\n        image,\n        begin=[f_coord, 0, 0, 0],\n        size=[1, image.shape[1], image.shape[2], image.shape[3]] \n    )\"\"\"\n\n    if image.ndim == 2:\n        specific_slice_tensor = image\n    else:\n        specific_slice_tensor = tf.slice(\n            image,\n            begin=[f_coord, 0, 0],\n            size=[1, image.shape[1], image.shape[2]]\n        )\n        # Squeeze to remove the extra dimension of size 1\n        specific_slice_tensor = tf.squeeze(specific_slice_tensor)\n    \n    expanded_image = tf.expand_dims(specific_slice_tensor, -1)\n    #m, M=tf.math.reduce_min(expanded_image), tf.math.reduce_max(expanded_image)\n    #expanded_image = (tf.image.grayscale_to_rgb(expanded_image)-m)/(M-m)\n    expanded_image = tf.image.grayscale_to_rgb(expanded_image)\n    expanded_image = tf.image.resize(expanded_image, (128,128))\n    #tf.print(\"expanded_image shape - \",expanded_image.shape)\n    sqzd_image = tf.squeeze(expanded_image)\n    #tf.print(\"sqzd_image shape - \", sqzd_image.shape)\n    return sqzd_image\n\ndef load_dicom_tf(filepath_tensor, f_coord_tensor=None):\n    \"\"\"\n    Wrapper function to call read_and_parse_dicom_files_tensorflow_train within a tf.data.Dataset pipeline.\n    \"\"\"\n    #if f_coord_tensor:\n    image = tf.py_function(\n        read_and_parse_dicom_files_tensorflow_train,\n        inp=[filepath_tensor, f_coord_tensor],\n        Tout=tf.float32 # Adjust Tout based on the expected output type of your image data\n    )\n    \n    \"\"\"else:\n        image = tf.py_function(\n            read_and_parse_dicom_files_tensorflow_train,\n            inp=[filepath_tensor],\n            Tout=tf.float32 # Adjust Tout based on the expected output type of your image data\n    )\"\"\"\n    # Ensure the shape is defined if known, as tf.py_function can lose shape info\n    # image.set_shape([128, 128]) # Example for a 2D image, adjust as needed\n    return image \n\ndef preprocessing(dcm_path, f_coord):\n    train_img = load_dicom_tf(dcm_path, f_coord)\n    #train_img = read_and_parse_dicom_files_tensorflow_train(dcm_path, f_coord)\n    train_img = tf.reshape(train_img, shape=(128, 128, 3))\n    return train_img\n\ndef load_dataset_tensorflow_train(dcm_path, f_coord=0):\n    image = preprocessing(dcm_path, f_coord)\n    return {\"images\": tf.cast(image, tf.float32), \"dcm_paths\": dcm_path}\n\ndef dict_to_tuple(inputs):\n    return inputs[\"images\"], inputs[\"dcm_paths\"]\n\ndef generate_tf_datasets(dicom_paths, batch_size = 8):\n    \n    image_dataset = tf.data.Dataset.from_tensor_slices((dicom_paths))\n    \n    image_ds = image_dataset.map(load_dataset_tensorflow_train, num_parallel_calls=tf.data.AUTOTUNE)\n    image_ds = image_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n    image_ds = image_ds.batch(batch_size=BATCH_SIZE, drop_remainder=False)\n    image_ds = image_ds.prefetch(tf.data.AUTOTUNE)\n    \n    return image_ds\n\ndef predict(series_path: str) -> pl.DataFrame | pd.DataFrame:\n    print(\"Starting with Series -> \",series_path)\n    all_filepaths = []\n    for root, _, files in os.walk(series_path):\n        for file in files:\n            if file.endswith('.dcm'):\n                all_filepaths.append(os.path.join(root, file))\n    all_filepaths.sort()\n    test_ds = generate_tf_datasets(all_filepaths, BATCH_SIZE)\n    \n    all_predictions = []\n    for dicoms, dcm_paths in test_ds:\n        #print(f\"Images: {dicoms.numpy().shape}, DCM Paths: {dcm_paths.shape}\")\n        batch_predictions = model.predict(dicoms.numpy())\n        for path, pred in zip(dcm_paths, batch_predictions):\n            #print(\"path is -\",path)\n            pred_copy = pred.copy().reshape(1, -1)\n            #pred_copy[0, 7] = 1 - pred_copy[0, 7]\n            data_dict = {'DICOM Path': path.numpy().decode('utf-8').split('/')[-2]}\n            data_dict.update({format_column_name(pos_dict[i]): float(pred) for i, pred in enumerate(pred_copy[0])})\n            all_predictions.append(data_dict)\n    \n    final_df = pl.DataFrame(all_predictions)\n    \n    final_df.columns = SUBMISSION_COLS\n    \n    final_df = final_df.group_by(\"SeriesInstanceUID\").agg(\n        pl.col(LABEL_COLS[0]).max().alias(LABEL_COLS[0]),\n        pl.col(LABEL_COLS[1]).max().alias(LABEL_COLS[1]),\n        pl.col(LABEL_COLS[2]).max().alias(LABEL_COLS[2]),\n        pl.col(LABEL_COLS[3]).max().alias(LABEL_COLS[3]),\n        pl.col(LABEL_COLS[4]).max().alias(LABEL_COLS[4]),\n        pl.col(LABEL_COLS[5]).max().alias(LABEL_COLS[5]),\n        pl.col(LABEL_COLS[6]).max().alias(LABEL_COLS[6]),\n        pl.col(LABEL_COLS[7]).max().alias(LABEL_COLS[7]),\n        pl.col(LABEL_COLS[8]).max().alias(LABEL_COLS[8]),\n        pl.col(LABEL_COLS[9]).max().alias(LABEL_COLS[9]),\n        pl.col(LABEL_COLS[10]).max().alias(LABEL_COLS[10]),\n        pl.col(LABEL_COLS[11]).max().alias(LABEL_COLS[11]),\n        pl.col(LABEL_COLS[12]).max().alias(LABEL_COLS[12]),\n        pl.col(LABEL_COLS[13]).max().alias(LABEL_COLS[13])\n    )\n\n    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n\n    return final_df.drop('SeriesInstanceUID')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:37:48.064574Z","iopub.execute_input":"2025-10-11T19:37:48.065084Z","iopub.status.idle":"2025-10-11T19:37:48.093093Z","shell.execute_reply.started":"2025-10-11T19:37:48.065051Z","shell.execute_reply":"2025-10-11T19:37:48.092235Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from datetime import datetime\n\nTEST_RUN = False\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\ndef get_all_subfolders(root_folder_path):\n    \"\"\"\n    Retrieves a list of all subfolders (including nested ones) within a given root folder.\n\n    Args:\n        root_folder_path (str): The path to the root folder.\n\n    Returns:\n        list: A list of strings, where each string is the full path to a subfolder.\n    \"\"\"\n    subfolders = []\n    for dirpath, dirnames, _ in os.walk(root_folder_path):\n        for dirname in dirnames:\n            subfolders.append(os.path.join(dirpath, dirname))\n    return subfolders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:38:01.847237Z","iopub.execute_input":"2025-10-11T19:38:01.847609Z","iopub.status.idle":"2025-10-11T19:38:01.854106Z","shell.execute_reply.started":"2025-10-11T19:38:01.847580Z","shell.execute_reply":"2025-10-11T19:38:01.852894Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"if TEST_RUN:\n    \n    # Example usage:\n    folder_to_scan = \"/kaggle/input/rsna-intracranial-aneurysm-detection/series\"  # Replace with the actual path\n    #all_series_for_runtime_test = get_all_subfolders(folder_to_scan)\n    print(\"all series list length\", len(all_series_for_runtime_test))\n    \n    start = 110\n    end = 210\n    \n    test_series = all_series_for_runtime_test[start:end]\n    print(\"test run - series list length\",len(test_series))\n    \n    start_main = datetime.now()\n    \n    for i in range(len(test_series)):\n        start = datetime.now()\n        df = predict(test_series[i])\n        now = datetime.now()\n        difference = (now - start).total_seconds()\n        print(\"finished processing for series {0} in {1} sec\".format(test_series[i], difference))\n    \n    now_main = datetime.now()\n    difference_main = (now_main - start_main).total_seconds()\n    print(\"finished processing all series in {0} sec\".format(difference_main))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:38:06.224678Z","iopub.execute_input":"2025-10-11T19:38:06.225083Z","iopub.status.idle":"2025-10-11T19:38:06.231823Z","shell.execute_reply.started":"2025-10-11T19:38:06.225060Z","shell.execute_reply":"2025-10-11T19:38:06.230608Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import kaggle_evaluation.rsna_inference_server\n#import shutil\n\nshutil.rmtree('/kaggle/shared', ignore_errors=True)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\ninference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    print(\"inside if\")\n    inference_server.serve()\nelse:\n    print(\"inside else\")\n    inference_server.run_local_gateway()\n    display(pl.read_parquet('/kaggle/working/submission.parquet'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T19:38:09.251012Z","iopub.execute_input":"2025-10-11T19:38:09.251857Z","iopub.status.idle":"2025-10-11T19:39:00.409144Z","shell.execute_reply.started":"2025-10-11T19:38:09.251827Z","shell.execute_reply":"2025-10-11T19:39:00.408305Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"inside else\nStarting with Series ->  /kaggle/shared/kaggle/input/rsna-intracranial-aneurysm-detection/kaggle_evaluation/series/1.2.826.0.1.3680043.8.498.10057359944432090722321480667591403108\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\nStarting with Series ->  /kaggle/shared/kaggle/input/rsna-intracranial-aneurysm-detection/kaggle_evaluation/series/1.2.826.0.1.3680043.8.498.10028406715369553772267826812576760572\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\nStarting with Series ->  /kaggle/shared/kaggle/input/rsna-intracranial-aneurysm-detection/kaggle_evaluation/series/1.2.826.0.1.3680043.8.498.10076849691931487952247065581008547232\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"shape: (3, 15)\n┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n│ SeriesIns ┆ Left Infr ┆ Right Inf ┆ Left Supr ┆ … ┆ Right     ┆ Basilar   ┆ Other     ┆ Aneurysm │\n│ tanceUID  ┆ aclinoid  ┆ raclinoid ┆ aclinoid  ┆   ┆ Posterior ┆ Tip       ┆ Posterior ┆ Present  │\n│ ---       ┆ Internal  ┆ Internal  ┆ Internal  ┆   ┆ Communica ┆ ---       ┆ Circulati ┆ ---      │\n│ str       ┆ Car…      ┆ Ca…       ┆ Car…      ┆   ┆ ting …    ┆ f64       ┆ on        ┆ f64      │\n│           ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆           ┆ ---       ┆          │\n│           ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆           ┆ f64       ┆          │\n╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n│ 1.2.826.0 ┆ 2.4794e-7 ┆ 9.4130e-7 ┆ 9.5877e-7 ┆ … ┆ 1.3214e-7 ┆ 2.3962e-7 ┆ 2.5796e-7 ┆ 6.7781e- │\n│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ 7        │\n│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 005…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 1.2.826.0 ┆ 0.044757  ┆ 0.000797  ┆ 0.671632  ┆ … ┆ 0.025329  ┆ 0.000082  ┆ 0.180954  ┆ 0.000028 │\n│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 002…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 1.2.826.0 ┆ 0.046096  ┆ 0.000304  ┆ 0.866077  ┆ … ┆ 0.028269  ┆ 0.000021  ┆ 0.175394  ┆ 0.000049 │\n│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n│ 007…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (3, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>SeriesInstanceUID</th><th>Left Infraclinoid Internal Carotid Artery</th><th>Right Infraclinoid Internal Carotid Artery</th><th>Left Supraclinoid Internal Carotid Artery</th><th>Right Supraclinoid Internal Carotid Artery</th><th>Left Middle Cerebral Artery</th><th>Right Middle Cerebral Artery</th><th>Anterior Communicating Artery</th><th>Left Anterior Cerebral Artery</th><th>Right Anterior Cerebral Artery</th><th>Left Posterior Communicating Artery</th><th>Right Posterior Communicating Artery</th><th>Basilar Tip</th><th>Other Posterior Circulation</th><th>Aneurysm Present</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;1.2.826.0.1.3680043.8.498.1005…</td><td>2.4794e-7</td><td>9.4130e-7</td><td>9.5877e-7</td><td>1.9084e-7</td><td>1.2903e-7</td><td>6.8205e-7</td><td>1.9818e-7</td><td>0.999994</td><td>2.3768e-7</td><td>6.6656e-7</td><td>1.3214e-7</td><td>2.3962e-7</td><td>2.5796e-7</td><td>6.7781e-7</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.1002…</td><td>0.044757</td><td>0.000797</td><td>0.671632</td><td>0.893731</td><td>0.996986</td><td>0.769319</td><td>0.001165</td><td>0.999994</td><td>0.079771</td><td>0.999824</td><td>0.025329</td><td>0.000082</td><td>0.180954</td><td>0.000028</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.1007…</td><td>0.046096</td><td>0.000304</td><td>0.866077</td><td>0.548068</td><td>0.643451</td><td>0.839234</td><td>0.000665</td><td>0.999994</td><td>0.098723</td><td>0.447356</td><td>0.028269</td><td>0.000021</td><td>0.175394</td><td>0.000049</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}