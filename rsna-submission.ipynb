{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install duckdb --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\n#!pip install python-gdcm\n#!pip install pylibjpeg\n#!pip install pylibjpeg-libjpeg==2.2.0\n#!pip install pylibjpeg-openjpeg==2.3.0\n#!pip install matplotlib==3.10.3\n#!pip install scikit-learn==1.7.0\n!pip install polars --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\n#!pip install pydicom\n\n#!pip install tensorflow-io==0.37.1\n!pip install tensorflow-io==0.37.1 --no-index --find-links=/kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow_io\n\n#!pip install tensorflow==2.16.1\n!pip install tensorflow==2.16.1 --no-index --find-links=/kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow\n# Don't need it while inference\n#!pip install tensorflow-tpu==2.16.1 --find-links=https://storage.googleapis.com/libtpu-tf-releases/index.html","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-03T15:42:34.260181Z","iopub.execute_input":"2025-10-03T15:42:34.260545Z","iopub.status.idle":"2025-10-03T15:44:00.838439Z","shell.execute_reply.started":"2025-10-03T15:42:34.260519Z","shell.execute_reply":"2025-10-03T15:44:00.836720Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\nRequirement already satisfied: duckdb in /usr/local/lib/python3.11/dist-packages (1.2.2)\nLooking in links: /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\nRequirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\nLooking in links: /kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow_io\nRequirement already satisfied: tensorflow-io==0.37.1 in /usr/local/lib/python3.11/dist-packages (0.37.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-io==0.37.1) (0.37.1)\nLooking in links: /kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow\nProcessing /kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow/tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.14.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (18.1.1)\nProcessing /kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow/ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from tensorflow==2.16.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (2.32.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.1.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (4.14.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.73.1)\nProcessing /kaggle/input/suman-tensorflow-working-combo/kaggle/working/mysitepackages/tensorflow/tensorboard-2.16.2-py3-none-any.whl (from tensorflow==2.16.1)\nRequirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (3.8.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.16.1) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.0.0->tensorflow==2.16.1) (0.16.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.1) (2025.6.15)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.8.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.1) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1) (2.19.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.16.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1) (0.1.2)\nInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.18.0\n    Uninstalling tensorflow-2.18.0:\n      Successfully uninstalled tensorflow-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\njax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.16.1 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.16.1 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\"\"\"!pip download tensorflow-io==0.37.1 -d /kaggle/working/mysitepackages/tensorflow_io\n!pip download tensorflow==2.16.1 -d /kaggle/working/mysitepackages/tensorflow\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"from zipfile import ZipFile\n\ndirName = '/kaggle/working/mysitepackages'\nzipName = 'tensorflow_working_combo.zip'\n\n# Create a ZipFile Object\nwith ZipFile(zipName, 'w') as zipObj:\n    # Iterate over all the files in directory\n    for folderName, subfolders, filenames in os.walk(dirName):\n        for filename in filenames:\n            if (filename != zipName):\n                # create complete filepath of file in directory\n                filePath = os.path.join(folderName, filename)\n                # Add file to zip\n                zipObj.write(filePath)\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"import pydicom\nfrom pydicom import dcmread\nfrom pydicom.dataset import FileDataset, FileMetaDataset\nfrom pydicom.uid import generate_uid, ImplicitVRLittleEndian\"\"\"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport polars as pl\nimport duckdb as dd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport cv2\nimport pickle\nimport gc\nimport ctypes\nfrom pathlib import Path\nimport logging\nimport json\nimport multiprocessing as mp\nfrom concurrent.futures import ProcessPoolExecutor\nimport datetime\nfrom typing import Tuple, Optional\nimport warnings\nwarnings.filterwarnings('ignore')\nimport shutil\n\n#from sklearn.model_selection import train_test_split\n#from sklearn.preprocessing import LabelEncoder\n#from sklearn.metrics import log_loss\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \nimport tensorflow as tf\nimport tensorflow_io as tfio\nfrom tensorflow import keras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T15:47:22.108483Z","iopub.execute_input":"2025-10-03T15:47:22.108895Z","iopub.status.idle":"2025-10-03T15:47:37.196203Z","shell.execute_reply.started":"2025-10-03T15:47:22.108855Z","shell.execute_reply":"2025-10-03T15:47:37.195093Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"print(tf.__version__)\nprint(tfio.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T15:47:51.990060Z","iopub.execute_input":"2025-10-03T15:47:51.990468Z","iopub.status.idle":"2025-10-03T15:47:51.995954Z","shell.execute_reply.started":"2025-10-03T15:47:51.990439Z","shell.execute_reply":"2025-10-03T15:47:51.994685Z"}},"outputs":[{"name":"stdout","text":"2.16.1\n0.37.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"model = keras.models.\\\nload_model(\"/kaggle/input/rsna-aneurysm-cta-base/tensorflow2/inception-v3-transfer-learning/1/rsna_aneurysm_keras_base.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T15:47:54.584226Z","iopub.execute_input":"2025-10-03T15:47:54.584570Z","iopub.status.idle":"2025-10-03T15:47:58.141439Z","shell.execute_reply.started":"2025-10-03T15:47:54.584545Z","shell.execute_reply":"2025-10-03T15:47:58.140466Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from multiprocessing import cpu_count\nn_cores = cpu_count()\nprint(f'Number of Logical CPU cores: {n_cores}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T15:48:03.173365Z","iopub.execute_input":"2025-10-03T15:48:03.173696Z","iopub.status.idle":"2025-10-03T15:48:03.179027Z","shell.execute_reply.started":"2025-10-03T15:48:03.173673Z","shell.execute_reply":"2025-10-03T15:48:03.178003Z"}},"outputs":[{"name":"stdout","text":"Number of Logical CPU cores: 4\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"allowed_tags = ['BitsAllocated', 'BitsStored', 'Rows', 'Columns', 'FrameOfReferenceUID', 'HighBit', 'ImageOrientationPatient'\n                , 'ImagePositionPatient', 'InstanceNumber', 'Modality', 'PhotometricInterpretation'\n                , 'PixelRepresentation', 'PixelSpacing', 'PlanarConfiguration', 'RescaleIntercept', 'RescaleSlope'\n                , 'RescaleType', 'SamplesPerPixel', 'SliceThickness', 'SpacingBetweenSlices']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T15:48:05.126456Z","iopub.execute_input":"2025-10-03T15:48:05.127760Z","iopub.status.idle":"2025-10-03T15:48:05.132513Z","shell.execute_reply.started":"2025-10-03T15:48:05.127727Z","shell.execute_reply":"2025-10-03T15:48:05.131454Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"pos_dict = {0: 'anterior_communicating_artery',\n 1: 'basilar_tip',\n 2: 'left_anterior_cerebral_artery',\n 3: 'left_infraclinoid_internal_carotid_artery',\n 4: 'left_middle_cerebral_artery',\n 5: 'left_posterior_communicating_artery',\n 6: 'left_supraclinoid_internal_carotid_artery',\n 7: 'aneurysm_present',\n 8: 'other_posterior_circulation',\n 9: 'right_anterior_cerebral_artery',\n 10: 'right_infraclinoid_internal_carotid_artery',\n 11: 'right_middle_cerebral_artery',\n 12: 'right_posterior_communicating_artery',\n 13: 'right_supraclinoid_internal_carotid_artery'}\n\nSUBMISSION_COLS = [\n    'SeriesInstanceUID',\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present',\n]\n\nLABEL_COLS = [\n    'Left Infraclinoid Internal Carotid Artery',\n    'Right Infraclinoid Internal Carotid Artery',\n    'Left Supraclinoid Internal Carotid Artery',\n    'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery',\n    'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery',\n    'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery',\n    'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery',\n    'Basilar Tip',\n    'Other Posterior Circulation',\n    'Aneurysm Present',\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T15:48:07.286743Z","iopub.execute_input":"2025-10-03T15:48:07.287092Z","iopub.status.idle":"2025-10-03T15:48:07.294400Z","shell.execute_reply.started":"2025-10-03T15:48:07.287066Z","shell.execute_reply":"2025-10-03T15:48:07.293306Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"BATCH_SIZE = 32\n\ndef format_column_name(snake_str):\n    \"\"\"Convert snake_case string to Title Case with spaces\"\"\"\n    # Split the string into words and capitalize each word\n    return ' '.join(word.capitalize() for word in snake_str.split('_'))\n\ndef process_cta(image: np.ndarray, dcm):\n    \"\"\"\n    Specific preprocessing for CTA\n    - Window/level optimization for vessel visualization\n    - Vessel enhancement\n    \"\"\"\n    # Get window settings (typical for CTA)\n    window_center = 100  # Typical for CTA\n    window_width = 700   # Typical for CTA\n    \n    # Override with DICOM values if available\n    if hasattr(dcm, 'WindowCenter') and hasattr(dcm, 'WindowWidth'):\n        window_center = dcm.WindowCenter\n        window_width = dcm.WindowWidth\n        \n        # Handle multiple window settings\n        if isinstance(window_center, pydicom.multival.MultiValue):\n            window_center = window_center[0]\n        if isinstance(window_width, pydicom.multival.MultiValue):\n            window_width = window_width[0]\n    \n    # Apply window/level\n    min_value = window_center - window_width // 2\n    max_value = window_center + window_width // 2\n    image = np.clip(image, min_value, max_value)\n    \n    # Normalize to [0,1]\n    image = (image - min_value) / (max_value - min_value + 1e-10)\n    \n    return image\n\ndef read_and_parse_dicom_files_tensorflow_train_cta(dcm_path, f_coord=None):\n    #print(\"dcm_path - \", dcm_path)\n    raw_image = tf.io.read_file(dcm_path)\n    image = tfio.image.decode_dicom_image(raw_image, scale='auto', dtype=tf.float32)\n\n    image = process_cta(image, dcm_path)\n\n    if np.any(np.isnan(image)):\n        print(f\"Warning: NaN values found in image {dcm_path}\")\n        \n    if np.any(np.isinf(image)):\n        print(f\"Warning: Infinite values found in image {dcm_path}\")\n    \n    specific_slice_tensor = tf.slice(\n        image,\n        begin=[f_coord, 0, 0, 0],\n        size=[1, image.shape[1], image.shape[2], image.shape[3]]\n    )\n    # Squeeze to remove the extra dimension of size 1\n    specific_slice_tensor = tf.squeeze(specific_slice_tensor)\n    \n    expanded_image = tf.expand_dims(specific_slice_tensor, -1)\n    m, M=tf.math.reduce_min(expanded_image), tf.math.reduce_max(expanded_image)\n    expanded_image = (tf.image.grayscale_to_rgb(expanded_image)-m)/(M-m)\n    expanded_image = tf.image.resize(expanded_image, (128,128))\n    sqzd_image = tf.squeeze(expanded_image)\n    return sqzd_image\n\ndef load_dicom_tf_cta(filepath_tensor, f_coord_tensor=None):\n    \"\"\"\n    Wrapper function to call read_and_parse_dicom_files_tensorflow_train within a tf.data.Dataset pipeline.\n    \"\"\"\n    #if f_coord_tensor:\n    image = tf.py_function(\n        read_and_parse_dicom_files_tensorflow_train_cta,\n        inp=[filepath_tensor, f_coord_tensor],\n        Tout=tf.float32 # Adjust Tout based on the expected output type of your image data\n    )\n    \"\"\"else:\n        image = tf.py_function(\n            read_and_parse_dicom_files_tensorflow_train,\n            inp=[filepath_tensor],\n            Tout=tf.float32 # Adjust Tout based on the expected output type of your image data\n    )\"\"\"\n    # Ensure the shape is defined if known, as tf.py_function can lose shape info\n    #image.set_shape([128, 128]) # Example for a 2D image, adjust as needed\n    return image \n\ndef preprocessing_cta(dcm_path, f_coord):\n    train_img = load_dicom_tf_cta(dcm_path, f_coord)\n    #train_img = read_and_parse_dicom_files_tensorflow_train(dcm_path, f_coord)\n    train_img = tf.reshape(train_img, shape=(128, 128, 3))\n    return train_img\n\ndef load_dataset_tensorflow_train_cta(dcm_path, f_coord=0):\n    image = preprocessing_cta(dcm_path, f_coord)\n    return {\"images\": tf.cast(image, tf.float32), \"dcm_paths\": dcm_path}\n\ndef dict_to_tuple(inputs):\n    return inputs[\"images\"], inputs[\"dcm_paths\"]\n\ndef generate_tf_datasets(dicom_paths, batch_size = 16):\n    \n    image_dataset = tf.data.Dataset.from_tensor_slices((dicom_paths))\n    \n    image_ds = image_dataset.map(load_dataset_tensorflow_train_cta, num_parallel_calls=tf.data.AUTOTUNE)\n    image_ds = image_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n    image_ds = image_ds.batch(batch_size=BATCH_SIZE, drop_remainder=False)\n    image_ds = image_ds.prefetch(tf.data.AUTOTUNE)\n    \n    return image_ds\n\ndef predict(series_path: str) -> pl.DataFrame | pd.DataFrame:\n    print(\"Starting with Series -> \",series_path)\n    all_filepaths = []\n    for root, _, files in os.walk(series_path):\n        for file in files:\n            if file.endswith('.dcm'):\n                all_filepaths.append(os.path.join(root, file))\n    all_filepaths.sort()\n    test_ds = generate_tf_datasets(all_filepaths, BATCH_SIZE)\n    \n    all_predictions = []\n    for dicoms, dcm_paths in test_ds:\n        #print(f\"Images: {dicoms.numpy().shape}, DCM Paths: {dcm_paths.shape}\")\n        batch_predictions = model.predict(dicoms.numpy())\n        for path, pred in zip(dcm_paths, batch_predictions):\n            #print(\"path is -\",path)\n            pred_copy = pred.copy().reshape(1, -1)\n            pred_copy[0, 7] = 1 - pred_copy[0, 7]\n            data_dict = {'DICOM Path': path.numpy().decode('utf-8').split('/')[-2]}\n            data_dict.update({format_column_name(pos_dict[i]): float(pred) for i, pred in enumerate(pred_copy[0])})\n            all_predictions.append(data_dict)\n    \n    final_df = pl.DataFrame(all_predictions)\n    \n    final_df.columns = SUBMISSION_COLS\n    \n    final_df = final_df.group_by(\"SeriesInstanceUID\").agg(\n        pl.col(LABEL_COLS[0]).max().alias(LABEL_COLS[0]),\n        pl.col(LABEL_COLS[1]).max().alias(LABEL_COLS[1]),\n        pl.col(LABEL_COLS[2]).max().alias(LABEL_COLS[2]),\n        pl.col(LABEL_COLS[3]).max().alias(LABEL_COLS[3]),\n        pl.col(LABEL_COLS[4]).max().alias(LABEL_COLS[4]),\n        pl.col(LABEL_COLS[5]).max().alias(LABEL_COLS[5]),\n        pl.col(LABEL_COLS[6]).max().alias(LABEL_COLS[6]),\n        pl.col(LABEL_COLS[7]).max().alias(LABEL_COLS[7]),\n        pl.col(LABEL_COLS[8]).max().alias(LABEL_COLS[8]),\n        pl.col(LABEL_COLS[9]).max().alias(LABEL_COLS[9]),\n        pl.col(LABEL_COLS[10]).max().alias(LABEL_COLS[10]),\n        pl.col(LABEL_COLS[11]).max().alias(LABEL_COLS[11]),\n        pl.col(LABEL_COLS[12]).max().alias(LABEL_COLS[12]),\n        pl.col(LABEL_COLS[13]).max().alias(LABEL_COLS[13])\n    )\n\n    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n\n    return final_df.drop('SeriesInstanceUID')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T15:48:45.457891Z","iopub.execute_input":"2025-10-03T15:48:45.458368Z","iopub.status.idle":"2025-10-03T15:48:45.484658Z","shell.execute_reply.started":"2025-10-03T15:48:45.458328Z","shell.execute_reply":"2025-10-03T15:48:45.483532Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from datetime import datetime\n\nTEST_RUN = True\n\nif TEST_RUN:\n    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n    def get_all_subfolders(root_folder_path):\n        \"\"\"\n        Retrieves a list of all subfolders (including nested ones) within a given root folder.\n    \n        Args:\n            root_folder_path (str): The path to the root folder.\n    \n        Returns:\n            list: A list of strings, where each string is the full path to a subfolder.\n        \"\"\"\n        subfolders = []\n        for dirpath, dirnames, _ in os.walk(root_folder_path):\n            for dirname in dirnames:\n                subfolders.append(os.path.join(dirpath, dirname))\n        return subfolders\n    \n    # Example usage:\n    folder_to_scan = \"/kaggle/input/rsna-intracranial-aneurysm-detection/series\"  # Replace with the actual path\n    all_series_for_runtime_test = get_all_subfolders(folder_to_scan)\n    print(\"all series list length\", len(all_series_for_runtime_test))\n    \n    start = 10\n    end = 2560\n    \n    test_series = all_series_for_runtime_test[start:end]\n    print(\"test run - series list length\",len(test_series))\n    \n    start_main = datetime.now()\n    \n    for i in range(len(test_series)):\n        start = datetime.now()\n        df = predict(test_series[i])\n        now = datetime.now()\n        difference = (now - start).total_seconds()\n        print(\"finished processing for series {0} in {1} sec\".format(test_series[i], difference))\n    \n    now_main = datetime.now()\n    difference_main = (now - start).total_seconds()\n    print(\"finished processing all series in {0} sec\".format(difference_main))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T15:48:51.188569Z","iopub.execute_input":"2025-10-03T15:48:51.188947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kaggle_evaluation.rsna_inference_server\nimport shutil\n\nshutil.rmtree('/kaggle/shared', ignore_errors=True)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n\ninference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    print(\"inside if\")\n    inference_server.serve()\nelse:\n    print(\"inside else\")\n    inference_server.run_local_gateway()\n    display(pl.read_parquet('/kaggle/working/submission.parquet'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}