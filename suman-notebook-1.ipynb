{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":99552,"databundleVersionId":13441085,"sourceType":"competition"},{"sourceId":8236972,"sourceType":"datasetVersion","datasetId":4885707},{"sourceId":12850999,"sourceType":"datasetVersion","datasetId":8127880}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sumaniitm/complete-train-metadata-using-duckdb-and-polars?scriptVersionId=261650391\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Installing required dependencies","metadata":{}},{"cell_type":"code","source":"!pip install duckdb --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\n!pip install python-gdcm\n!pip install pylibjpeg\n!pip install pylibjpeg-libjpeg==2.2.0\n!pip install pylibjpeg-openjpeg==2.3.0\n!pip install matplotlib==3.10.3\n!pip install scikit-learn==1.7.0\n!pip install polars --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\n!pip install pydicom","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:22:20.519881Z","iopub.execute_input":"2025-09-13T18:22:20.520173Z","iopub.status.idle":"2025-09-13T18:23:00.395302Z","shell.execute_reply.started":"2025-09-13T18:22:20.520147Z","shell.execute_reply":"2025-09-13T18:23:00.389649Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\nProcessing /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg/duckdb-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nInstalling collected packages: duckdb\nSuccessfully installed duckdb-0.8.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting python-gdcm\n  Downloading python_gdcm-3.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: python-gdcm\nSuccessfully installed python-gdcm-3.2.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting pylibjpeg\n  Downloading pylibjpeg-2.1.0-py3-none-any.whl (25 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from pylibjpeg) (2.0.2)\nInstalling collected packages: pylibjpeg\nSuccessfully installed pylibjpeg-2.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting pylibjpeg-libjpeg==2.2.0\n  Downloading pylibjpeg_libjpeg-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from pylibjpeg-libjpeg==2.2.0) (2.0.2)\nInstalling collected packages: pylibjpeg-libjpeg\nSuccessfully installed pylibjpeg-libjpeg-2.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting pylibjpeg-openjpeg==2.3.0\n  Downloading pylibjpeg_openjpeg-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from pylibjpeg-openjpeg==2.3.0) (2.0.2)\nInstalling collected packages: pylibjpeg-openjpeg\nSuccessfully installed pylibjpeg-openjpeg-2.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: matplotlib==3.10.3 in /usr/local/lib/python3.10/site-packages (3.10.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (3.2.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (25.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (2.9.0.post0)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (4.58.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (1.3.2)\nRequirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (2.0.2)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (11.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.10.3) (1.17.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: scikit-learn==1.7.0 in /usr/local/lib/python3.10/site-packages (1.7.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.7.0) (3.6.0)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.7.0) (1.5.1)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.7.0) (1.15.3)\nRequirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.7.0) (2.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nLooking in links: /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\nProcessing /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg/polars-0.20.16-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nInstalling collected packages: polars\nSuccessfully installed polars-0.20.16\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting pydicom\n  Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pydicom\nSuccessfully installed pydicom-3.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Importing required libraries","metadata":{}},{"cell_type":"code","source":"from pydicom import dcmread\nfrom pydicom.dataset import FileDataset, FileMetaDataset\nfrom pydicom.uid import generate_uid, ImplicitVRLittleEndian\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport polars as pl\nimport duckdb as dd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport cv2\nimport pickle\nimport gc\nimport ctypes\nfrom pathlib import Path\nimport logging\nimport json\nimport multiprocessing as mp\nfrom concurrent.futures import ProcessPoolExecutor\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss\nimport tensorflow as tf\nimport tensorflow_io as tfio\nfrom tensorflow import keras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:23:04.593634Z","iopub.execute_input":"2025-09-13T18:23:04.593917Z","iopub.status.idle":"2025-09-13T18:23:29.368807Z","shell.execute_reply.started":"2025-09-13T18:23:04.59389Z","shell.execute_reply":"2025-09-13T18:23:29.364524Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1757787796.396342      10 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:230\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(tf.__version__)\nprint(tfio.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:23:33.567177Z","iopub.execute_input":"2025-09-13T18:23:33.567698Z","iopub.status.idle":"2025-09-13T18:23:33.578479Z","shell.execute_reply.started":"2025-09-13T18:23:33.567671Z","shell.execute_reply":"2025-09-13T18:23:33.572651Z"}},"outputs":[{"name":"stdout","text":"2.18.0\n0.37.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Initializing the TPU","metadata":{}},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)\n\nprint(\"Number of accelerators: \", tpu_strategy.num_replicas_in_sync)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:23:38.118984Z","iopub.execute_input":"2025-09-13T18:23:38.119295Z","iopub.status.idle":"2025-09-13T18:23:46.634629Z","shell.execute_reply.started":"2025-09-13T18:23:38.119272Z","shell.execute_reply":"2025-09-13T18:23:46.630746Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1757787822.308845      10 service.cc:148] XLA service 0x58d0c347c8b0 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1757787822.308891      10 service.cc:156]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1757787822.308896      10 service.cc:156]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1757787822.308899      10 service.cc:156]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1757787822.308901      10 service.cc:156]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1757787822.308904      10 service.cc:156]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1757787822.308907      10 service.cc:156]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1757787822.308910      10 service.cc:156]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1757787822.308914      10 service.cc:156]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nNumber of accelerators:  8\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Setting polars configs to view the dataframes better","metadata":{}},{"cell_type":"code","source":"pl.Config(fmt_str_lengths=1000)\npl.Config.set_tbl_rows(1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:23:50.517062Z","iopub.execute_input":"2025-09-13T18:23:50.517377Z","iopub.status.idle":"2025-09-13T18:23:50.532397Z","shell.execute_reply.started":"2025-09-13T18:23:50.517352Z","shell.execute_reply":"2025-09-13T18:23:50.528544Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"polars.config.Config"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Load the metadata of the training images\n## Also separate out the localizer coordinates into individual columns","metadata":{}},{"cell_type":"code","source":"train_meta_data = pl.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\\\n                              , low_memory=True)\n\ntrain_locale_meta_data = pl.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv'\\\n                              , low_memory=True)\n\ndef parse_coordinates(coord_str):\n    if coord_str is None:\n        return None, None\n    try:\n        coord_dict = json.loads(coord_str.replace(\"'\", '\"'))\n        return float(coord_dict.get('x', 0.0)), float(coord_dict.get('y', 0.0)), int(coord_dict.get('f', 0.0))\n    except (json.JSONDecodeError, KeyError, ValueError, AttributeError):\n        return None, None\n\ntrain_locale_meta_data = train_locale_meta_data.with_columns([\n    pl.col(\"coordinates\")\n    .map_elements(lambda x: parse_coordinates(x)[0], return_dtype=pl.Float64)\n    .cast(pl.Float64)\n    .alias(\"coordinates_x\"),\n    \n    pl.col(\"coordinates\")\n    .map_elements(lambda x: parse_coordinates(x)[1], return_dtype=pl.Float64)\n    .cast(pl.Float64)\n    .alias(\"coordinates_y\"),\n    \n    pl.col(\"coordinates\")\n    .map_elements(lambda x: parse_coordinates(x)[2], return_dtype=pl.Int32)\n    .cast(pl.Int32)\n    .alias(\"coordinates_f\")\n])\n\nprint(\"Train CSV shape : \", train_meta_data.shape)\nprint(\"Train Localizers CSV shape : \", train_locale_meta_data.shape)\n# Show the first few rows\nprint(train_locale_meta_data.filter(pl.col('coordinates_f') != 0.0)\\\n      .select([\"coordinates\", \"coordinates_x\", \"coordinates_y\", \"coordinates_f\"]).head(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:23:55.337226Z","iopub.execute_input":"2025-09-13T18:23:55.337541Z","iopub.status.idle":"2025-09-13T18:23:55.519189Z","shell.execute_reply.started":"2025-09-13T18:23:55.337516Z","shell.execute_reply":"2025-09-13T18:23:55.514369Z"}},"outputs":[{"name":"stdout","text":"Train CSV shape :  (4348, 18)\nTrain Localizers CSV shape :  (2249, 7)\nshape: (5, 4)\n┌────────────────────────────────┬───────────────┬───────────────┬───────────────┐\n│ coordinates                    ┆ coordinates_x ┆ coordinates_y ┆ coordinates_f │\n│ ---                            ┆ ---           ┆ ---           ┆ ---           │\n│ str                            ┆ f64           ┆ f64           ┆ i32           │\n╞════════════════════════════════╪═══════════════╪═══════════════╪═══════════════╡\n│ {'x': 272.41014419367286, 'y': ┆ 272.410144    ┆ 194.117971    ┆ 57            │\n│ 194.11797116126544, 'f': 57}   ┆               ┆               ┆               │\n│ {'x': 262.09232271634613, 'y': ┆ 262.092323    ┆ 208.984615    ┆ 7             │\n│ 208.98461538461538, 'f': 7}    ┆               ┆               ┆               │\n│ {'x': 287.35893155258765, 'y': ┆ 287.358932    ┆ 205.382304    ┆ 73            │\n│ 205.38230383973288, 'f': 73}   ┆               ┆               ┆               │\n│ {'x': 245.43308996029836, 'y': ┆ 245.43309     ┆ 186.103242    ┆ 8             │\n│ 186.10324187733096, 'f': 8}    ┆               ┆               ┆               │\n│ {'x': 350.3838383838384, 'y':  ┆ 350.383838    ┆ 191.353535    ┆ 81            │\n│ 191.35353535353536, 'f': 81}   ┆               ┆               ┆               │\n└────────────────────────────────┴───────────────┴───────────────┴───────────────┘\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Glancing at the datasets so far","metadata":{}},{"cell_type":"code","source":"train_meta_data.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:40:50.472469Z","iopub.execute_input":"2025-09-13T18:40:50.47285Z","iopub.status.idle":"2025-09-13T18:40:50.496173Z","shell.execute_reply.started":"2025-09-13T18:40:50.47282Z","shell.execute_reply":"2025-09-13T18:40:50.48971Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"shape: (10, 18)\n┌───────────┬───────────┬───────────┬──────────┬───┬───────────┬───────────┬───────────┬───────────┐\n│ SeriesIns ┆ PatientAg ┆ PatientSe ┆ Modality ┆ … ┆ Right     ┆ Basilar   ┆ Other     ┆ Aneurysm  │\n│ tanceUID  ┆ e         ┆ x         ┆ ---      ┆   ┆ Posterior ┆ Tip       ┆ Posterior ┆ Present   │\n│ ---       ┆ ---       ┆ ---       ┆ str      ┆   ┆ Communica ┆ ---       ┆ Circulati ┆ ---       │\n│ str       ┆ i64       ┆ str       ┆          ┆   ┆ ting      ┆ i64       ┆ on        ┆ i64       │\n│           ┆           ┆           ┆          ┆   ┆ Artery    ┆           ┆ ---       ┆           │\n│           ┆           ┆           ┆          ┆   ┆ ---       ┆           ┆ i64       ┆           │\n│           ┆           ┆           ┆          ┆   ┆ i64       ┆           ┆           ┆           │\n╞═══════════╪═══════════╪═══════════╪══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n│ 1.2.826.0 ┆ 64        ┆ Female    ┆ MRA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 000404442 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 802350510 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 837515287 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 810765664 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 7         ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1.2.826.0 ┆ 76        ┆ Female    ┆ MRA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 000468422 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 489439767 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 990184165 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 695465008 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 5         ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1.2.826.0 ┆ 58        ┆ Male      ┆ CTA      ┆ … ┆ 0         ┆ 0         ┆ 1         ┆ 1         │\n│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 000515860 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 391200942 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 563547310 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 034407731 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 7         ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1.2.826.0 ┆ 71        ┆ Male      ┆ MRA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 000938310 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 806879548 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 874153324 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 491437018 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 2         ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1.2.826.0 ┆ 48        ┆ Female    ┆ MRA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 001279003 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 541051840 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 040083439 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 524285365 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 7         ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1.2.826.0 ┆ 53        ┆ Female    ┆ CTA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 001475765 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 833505476 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 647995799 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 211262596 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1         ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1.2.826.0 ┆ 55        ┆ Female    ┆ CTA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 002141124 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 800551332 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 123664746 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 023913790 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 6         ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1.2.826.0 ┆ 51        ┆ Female    ┆ MRA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0         │\n│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 002268809 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 773189407 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 951093096 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 643281810 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 5         ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1.2.826.0 ┆ 78        ┆ Male      ┆ CTA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 1         │\n│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 002279628 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 069853422 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 175847320 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 802483883 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1         ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 1.2.826.0 ┆ 76        ┆ Female    ┆ MRA      ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 1         │\n│ .1.368004 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 3.8.498.1 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 002341116 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 459066467 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 853404403 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 696371663 ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n│ 6         ┆           ┆           ┆          ┆   ┆           ┆           ┆           ┆           │\n└───────────┴───────────┴───────────┴──────────┴───┴───────────┴───────────┴───────────┴───────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (10, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>SeriesInstanceUID</th><th>PatientAge</th><th>PatientSex</th><th>Modality</th><th>Left Infraclinoid Internal Carotid Artery</th><th>Right Infraclinoid Internal Carotid Artery</th><th>Left Supraclinoid Internal Carotid Artery</th><th>Right Supraclinoid Internal Carotid Artery</th><th>Left Middle Cerebral Artery</th><th>Right Middle Cerebral Artery</th><th>Anterior Communicating Artery</th><th>Left Anterior Cerebral Artery</th><th>Right Anterior Cerebral Artery</th><th>Left Posterior Communicating Artery</th><th>Right Posterior Communicating Artery</th><th>Basilar Tip</th><th>Other Posterior Circulation</th><th>Aneurysm Present</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;1.2.826.0.1.3680043.8.498.10004044428023505108375152878107656647&quot;</td><td>64</td><td>&quot;Female&quot;</td><td>&quot;MRA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.10004684224894397679901841656954650085&quot;</td><td>76</td><td>&quot;Female&quot;</td><td>&quot;MRA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.10005158603912009425635473100344077317&quot;</td><td>58</td><td>&quot;Male&quot;</td><td>&quot;CTA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.10009383108068795488741533244914370182&quot;</td><td>71</td><td>&quot;Male&quot;</td><td>&quot;MRA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.10012790035410518400400834395242853657&quot;</td><td>48</td><td>&quot;Female&quot;</td><td>&quot;MRA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.10014757658335054766479957992112625961&quot;</td><td>53</td><td>&quot;Female&quot;</td><td>&quot;CTA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.10021411248005513321236647460239137906&quot;</td><td>55</td><td>&quot;Female&quot;</td><td>&quot;CTA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.10022688097731894079510930966432818105&quot;</td><td>51</td><td>&quot;Female&quot;</td><td>&quot;MRA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.10022796280698534221758473208024838831&quot;</td><td>78</td><td>&quot;Male&quot;</td><td>&quot;CTA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.10023411164590664678534044036963716636&quot;</td><td>76</td><td>&quot;Female&quot;</td><td>&quot;MRA&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"train_locale_meta_data.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Get summary statistics of the new columns","metadata":{}},{"cell_type":"code","source":"print(train_locale_meta_data.select([\"coordinates_x\", \"coordinates_y\", \"coordinates_f\"]).describe())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Get the image metadata from each training series and create a dataframe out of them","metadata":{}},{"cell_type":"code","source":"allowed_tags = ['BitsAllocated', 'BitsStored', 'Rows', 'Columns', 'FrameOfReferenceUID', 'HighBit', 'ImageOrientationPatient'\n                , 'ImagePositionPatient', 'InstanceNumber', 'Modality', 'PhotometricInterpretation'\n                , 'PixelRepresentation', 'PixelSpacing', 'PlanarConfiguration', 'RescaleIntercept', 'RescaleSlope'\n                , 'RescaleType', 'SamplesPerPixel', 'SliceThickness', 'SpacingBetweenSlices']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:24:02.216945Z","iopub.execute_input":"2025-09-13T18:24:02.217256Z","iopub.status.idle":"2025-09-13T18:24:02.229366Z","shell.execute_reply.started":"2025-09-13T18:24:02.217231Z","shell.execute_reply":"2025-09-13T18:24:02.222634Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Functions to collect metadata without the image arrays\n### We use python slots to reduce the memory foorprint\n### Also use multithreading to speed up processing","metadata":{}},{"cell_type":"code","source":"class DicomRecord:\n    \"\"\"\n    Memory-efficient class for storing DICOM metadata using __slots__\n    \"\"\"\n    __slots__ = ['folder_name', 'file_name', 'file_path', 'image_shape'] + [\n        'BitsAllocated', 'BitsStored', 'Rows', 'Columns', 'FrameOfReferenceUID',\n        'HighBit', 'ImageOrientationPatient', 'ImagePositionPatient', 'InstanceNumber',\n        'Modality', 'PhotometricInterpretation', 'PixelRepresentation', 'PixelSpacing',\n        'PlanarConfiguration', 'RescaleIntercept', 'RescaleSlope', 'RescaleType',\n        'SamplesPerPixel', 'SliceThickness', 'SpacingBetweenSlices'\n    ]\n    \n    def __init__(self, folder_name, file_name, file_path, image_shape):\n        self.folder_name = folder_name\n        self.file_name = file_name\n        self.file_path = file_path\n        self.image_shape = image_shape\n        for tag in self.__slots__[4:]:  \n            setattr(self, tag, None)\n    \n    def to_dict(self):\n        return {slot: getattr(self, slot) for slot in self.__slots__}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:24:07.231738Z","iopub.execute_input":"2025-09-13T18:24:07.232029Z","iopub.status.idle":"2025-09-13T18:24:07.245788Z","shell.execute_reply.started":"2025-09-13T18:24:07.231997Z","shell.execute_reply":"2025-09-13T18:24:07.240345Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def process_single_folder(folder_path, allowed_tags):\n    \"\"\"\n    Process a single folder of DICOM files and save image arrays\n    \"\"\"\n    try:\n        data = []\n        dcm_files = list(Path(folder_path).glob(\"*.dcm\"))\n        folder_name = Path(folder_path).name\n        \n        for dcm_file in dcm_files:\n            try:\n                # Read DICOM file\n                ds = dcmread(str(dcm_file))\n                original_shape = str(ds.pixel_array.shape)\n                \n                # Create record\n                record = DicomRecord(folder_name, dcm_file.name, str(dcm_file), original_shape)\n                \n                # Fill in tags\n                for tag in allowed_tags:\n                    try:\n                        value = getattr(ds, tag)\n                        if hasattr(value, '__iter__') and not isinstance(value, str):\n                            value = str(list(map(str, value)))\n                        else:\n                            value = str(value)\n                        setattr(record, tag, value)\n                    except (AttributeError, TypeError):\n                        continue\n                \n                data.append(record.to_dict())\n                \n            except Exception as e:\n                print(f\"Error processing file {dcm_file}: {e}\")\n                continue\n                \n        return data\n        \n    except Exception as e:\n        print(f\"Error processing folder {folder_path}: {e}\")\n        return []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:24:10.397185Z","iopub.execute_input":"2025-09-13T18:24:10.397467Z","iopub.status.idle":"2025-09-13T18:24:10.409592Z","shell.execute_reply.started":"2025-09-13T18:24:10.397444Z","shell.execute_reply":"2025-09-13T18:24:10.406178Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def create_dicom_dataset(root_folder, allowed_tags, num_processes=None, chunk_size=100):\n    \"\"\"\n    Create dataset with metadata DataFrame and memory-mapped image arrays\n    \"\"\"\n    root_path = Path(root_folder)\n    folders = [f for f in root_path.iterdir() if f.is_dir()]\n    \n    if not num_processes:\n        num_processes = mp.cpu_count()\n    \n    # Create directories for temporary and array storage\n    temp_dir = Path(\"temp_chunks\")\n    temp_dir.mkdir(exist_ok=True)\n    \n    # Create schema\n    schema = {\n        'folder_name': pl.Utf8,\n        'file_name': pl.Utf8,\n        'file_path': pl.String,\n        'image_shape': pl.String\n    }\n    schema.update({tag: pl.Utf8 for tag in allowed_tags})\n    \n    # Process folders in parallel\n    with ProcessPoolExecutor(max_workers=num_processes) as executor:\n        for i in range(0, len(folders), chunk_size):\n            chunk_folders = folders[i:i+chunk_size]\n            chunk_data = []\n            \n            futures = [\n                executor.submit(\n                    process_single_folder, \n                    str(folder), \n                    allowed_tags\n                    #arrays_dir\n                )\n                for folder in chunk_folders\n            ]\n            \n            for future in tqdm(futures, \n                             desc=f\"Processing chunk {i//chunk_size + 1}/{(len(folders)-1)//chunk_size + 1}\"):\n                chunk_data.extend(future.result())\n            \n            if chunk_data:\n                chunk_df = pl.DataFrame(\n                    chunk_data,\n                    schema=schema,\n                    infer_schema_length=None\n                )\n                \n                chunk_df.write_parquet(\n                    temp_dir / f\"dicom_metadata_chunk_{i//chunk_size}.parquet\",\n                    compression=\"snappy\"\n                )\n                \n                del chunk_data\n                del chunk_df\n    \n    # Combine chunks\n    print(\"\\nCombining chunks...\")\n    chunk_files = list(temp_dir.glob(\"dicom_metadata_chunk_*.parquet\"))\n    final_df = pl.concat([\n        pl.scan_parquet(str(chunk_file))\n        for chunk_file in chunk_files\n    ]).collect()\n    \n    # Clean up temporary files\n    for f in chunk_files:\n        f.unlink()\n    temp_dir.rmdir()\n    \n    return final_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:24:15.30434Z","iopub.execute_input":"2025-09-13T18:24:15.304657Z","iopub.status.idle":"2025-09-13T18:24:15.319609Z","shell.execute_reply.started":"2025-09-13T18:24:15.304632Z","shell.execute_reply":"2025-09-13T18:24:15.316139Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Starting the collection of metadata","metadata":{}},{"cell_type":"code","source":"with tpu_strategy.scope():\n    root_folder = \"/kaggle/input/rsna-intracranial-aneurysm-detection/series\"\n    \n    try:\n        metadata_df = create_dicom_dataset(\n            root_folder, \n            allowed_tags, \n            num_processes=mp.cpu_count(),\n            chunk_size=192\n        )\n    except Exception as e:\n        print(f\"Error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:24:27.142555Z","iopub.execute_input":"2025-09-13T18:24:27.142861Z","iopub.status.idle":"2025-09-13T18:37:45.240001Z","shell.execute_reply.started":"2025-09-13T18:24:27.142837Z","shell.execute_reply":"2025-09-13T18:37:45.235355Z"}},"outputs":[{"name":"stderr","text":"Processing chunk 1/23: 100%|██████████| 192/192 [00:33<00:00,  5.82it/s]\nProcessing chunk 2/23: 100%|██████████| 192/192 [00:28<00:00,  6.79it/s]\nProcessing chunk 3/23: 100%|██████████| 192/192 [00:32<00:00,  5.96it/s]\nProcessing chunk 4/23: 100%|██████████| 192/192 [00:35<00:00,  5.48it/s]\nProcessing chunk 5/23: 100%|██████████| 192/192 [00:37<00:00,  5.15it/s]\nProcessing chunk 6/23: 100%|██████████| 192/192 [00:36<00:00,  5.28it/s]\nProcessing chunk 7/23: 100%|██████████| 192/192 [00:32<00:00,  5.91it/s]\nProcessing chunk 8/23: 100%|██████████| 192/192 [00:33<00:00,  5.73it/s]\nProcessing chunk 9/23: 100%|██████████| 192/192 [00:31<00:00,  6.18it/s]\nProcessing chunk 10/23: 100%|██████████| 192/192 [00:33<00:00,  5.69it/s]\nProcessing chunk 11/23: 100%|██████████| 192/192 [00:32<00:00,  5.89it/s]\nProcessing chunk 12/23: 100%|██████████| 192/192 [00:41<00:00,  4.65it/s]\nProcessing chunk 13/23: 100%|██████████| 192/192 [00:32<00:00,  5.94it/s]\nProcessing chunk 14/23: 100%|██████████| 192/192 [00:31<00:00,  6.18it/s]\nProcessing chunk 15/23: 100%|██████████| 192/192 [00:32<00:00,  5.89it/s]\nProcessing chunk 16/23: 100%|██████████| 192/192 [00:36<00:00,  5.21it/s]\nProcessing chunk 17/23: 100%|██████████| 192/192 [00:39<00:00,  4.92it/s]\nProcessing chunk 18/23: 100%|██████████| 192/192 [00:32<00:00,  5.94it/s]\nProcessing chunk 19/23: 100%|██████████| 192/192 [00:38<00:00,  4.97it/s]\nProcessing chunk 20/23: 100%|██████████| 192/192 [00:35<00:00,  5.40it/s]\nProcessing chunk 21/23: 100%|██████████| 192/192 [00:30<00:00,  6.30it/s]\nProcessing chunk 22/23: 100%|██████████| 192/192 [00:31<00:00,  6.05it/s]\nProcessing chunk 23/23: 100%|██████████| 124/124 [00:26<00:00,  4.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nCombining chunks...\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"metadata_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:39:08.142371Z","iopub.execute_input":"2025-09-13T18:39:08.142711Z","iopub.status.idle":"2025-09-13T18:39:08.156822Z","shell.execute_reply.started":"2025-09-13T18:39:08.142688Z","shell.execute_reply":"2025-09-13T18:39:08.152191Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['folder_name',\n 'file_name',\n 'file_path',\n 'image_shape',\n 'BitsAllocated',\n 'BitsStored',\n 'Rows',\n 'Columns',\n 'FrameOfReferenceUID',\n 'HighBit',\n 'ImageOrientationPatient',\n 'ImagePositionPatient',\n 'InstanceNumber',\n 'Modality',\n 'PhotometricInterpretation',\n 'PixelRepresentation',\n 'PixelSpacing',\n 'PlanarConfiguration',\n 'RescaleIntercept',\n 'RescaleSlope',\n 'RescaleType',\n 'SamplesPerPixel',\n 'SliceThickness',\n 'SpacingBetweenSlices']"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# Create the full training data\n* Bring in the localizer coordinates for the series where aneurysm is present\n* Create another column to signify whether aneurysm is shown in a specific image within a series\n* There can be cases where some images of a series cannot catch aneurysm presence\n* Bringing all the rows at the image file granularity, i.e. if a file has coordinates then it has aneurysm else not","metadata":{}},{"cell_type":"code","source":"df_all_coordinates = dd.sql( \\\n    \"select t2.coordinates_x, t2.coordinates_y, t2.coordinates_f, t1.* \\\n    from metadata_df t1 \\\n    left join train_locale_meta_data t2 \\\n    on t1.folder_name = t2.SeriesInstanceUID \\\n    and replace(t1.file_name, '.dcm','') = t2.SOPInstanceUID \"\\\n).pl()\n\nprint(df_all_coordinates.shape)\nprint(df_all_coordinates.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:39:24.270336Z","iopub.execute_input":"2025-09-13T18:39:24.270739Z","iopub.status.idle":"2025-09-13T18:39:28.114151Z","shell.execute_reply.started":"2025-09-13T18:39:24.270709Z","shell.execute_reply":"2025-09-13T18:39:28.109546Z"}},"outputs":[{"name":"stdout","text":"(1001343, 27)\n['coordinates_x', 'coordinates_y', 'coordinates_f', 'folder_name', 'file_name', 'file_path', 'image_shape', 'BitsAllocated', 'BitsStored', 'Rows', 'Columns', 'FrameOfReferenceUID', 'HighBit', 'ImageOrientationPatient', 'ImagePositionPatient', 'InstanceNumber', 'Modality', 'PhotometricInterpretation', 'PixelRepresentation', 'PixelSpacing', 'PlanarConfiguration', 'RescaleIntercept', 'RescaleSlope', 'RescaleType', 'SamplesPerPixel', 'SliceThickness', 'SpacingBetweenSlices']\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"new_columns = [col.lower().replace(\" \", \"_\") for col in train_meta_data.columns]\ntrain_meta_data.columns = new_columns\nprint(train_meta_data.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:44:13.620554Z","iopub.execute_input":"2025-09-13T18:44:13.620939Z","iopub.status.idle":"2025-09-13T18:44:13.63417Z","shell.execute_reply.started":"2025-09-13T18:44:13.620911Z","shell.execute_reply":"2025-09-13T18:44:13.628032Z"}},"outputs":[{"name":"stdout","text":"['seriesinstanceuid', 'patientage', 'patientsex', 'modality', 'left_infraclinoid_internal_carotid_artery', 'right_infraclinoid_internal_carotid_artery', 'left_supraclinoid_internal_carotid_artery', 'right_supraclinoid_internal_carotid_artery', 'left_middle_cerebral_artery', 'right_middle_cerebral_artery', 'anterior_communicating_artery', 'left_anterior_cerebral_artery', 'right_anterior_cerebral_artery', 'left_posterior_communicating_artery', 'right_posterior_communicating_artery', 'basilar_tip', 'other_posterior_circulation', 'aneurysm_present']\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"df_all_data = dd.sql( \\\n    \"select t2.file_name, t2.image_shape, t2.coordinates_x, t2.coordinates_y, t2.coordinates_f \\\n    , t1.aneurysm_present as aneurysm_present_in_series \\\n    , case when t2.coordinates_x is not null then 1 else 0 end as aneurysm_present_in_image \\\n    , t1.seriesinstanceuid, t1.patientage, t1.patientsex, t1.modality \\\n    , case when t2.coordinates_x is not null then t1.left_infraclinoid_internal_carotid_artery \\\n    else 0 end as left_infraclinoid_internal_carotid_artery \\\n    , case when t2.coordinates_x is not null then t1.right_infraclinoid_internal_carotid_artery \\\n    else 0 end as right_infraclinoid_internal_carotid_artery \\\n    , case when t2.coordinates_x is not null then t1.left_supraclinoid_internal_carotid_artery \\\n    else 0 end as left_supraclinoid_internal_carotid_artery \\\n    , case when t2.coordinates_x is not null then t1.right_supraclinoid_internal_carotid_artery \\\n    else 0 end as right_supraclinoid_internal_carotid_artery \\\n    , case when t2.coordinates_x is not null then t1.left_middle_cerebral_artery \\\n    else 0 end as left_middle_cerebral_artery \\\n    , case when t2.coordinates_x is not null then t1.right_middle_cerebral_artery \\\n    else 0 end as right_middle_cerebral_artery \\\n    , case when t2.coordinates_x is not null then t1.anterior_communicating_artery \\\n    else 0 end as anterior_communicating_artery \\\n    , case when t2.coordinates_x is not null then t1.left_anterior_cerebral_artery \\\n    else 0 end as left_anterior_cerebral_artery \\\n    , case when t2.coordinates_x is not null then t1.right_anterior_cerebral_artery \\\n    else 0 end as right_anterior_cerebral_artery \\\n    , case when t2.coordinates_x is not null then t1.left_posterior_communicating_artery \\\n    else 0 end as left_posterior_communicating_artery \\\n    , case when t2.coordinates_x is not null then t1.right_posterior_communicating_artery \\\n    else 0 end as right_posterior_communicating_artery \\\n    , case when t2.coordinates_x is not null then t1.basilar_tip \\\n    else 0 end as basilar_tip \\\n    , case when t2.coordinates_x is not null then t1.other_posterior_circulation \\\n    else 0 end as other_posterior_circulation \\\n    from train_meta_data t1 \\\n    join df_all_coordinates t2 \\\n    on t1.SeriesInstanceUID = t2.folder_name\" \\\n).pl()\n\nprint(\"Full training data: \", df_all_data.shape)\nprint(\"Full training data columns: \", df_all_data.columns)\nprint(\"Aneurysm not present in {0} series\".format(df_all_data.filter(pl.col(\"coordinates_x\").is_null()).shape[0]))\n\nprint(\"Aneurysm present in {0} series\".format(df_all_data.filter(pl.col(\"coordinates_x\").is_not_null()).shape[0]))\n\nprint(\"Aneurysm not shown in {0} images\".format(df_all_data.filter(pl.col(\"aneurysm_present_in_image\")==0).shape[0]))\n\nprint(\"Aneurysm shown in {0} images\".format(df_all_data.filter(pl.col(\"aneurysm_present_in_image\")==1).shape[0]))\n\nprint(df_all_data.select([\"coordinates_x\", \"coordinates_y\"]).describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-13T18:44:20.133372Z","iopub.execute_input":"2025-09-13T18:44:20.133722Z","iopub.status.idle":"2025-09-13T18:44:23.286895Z","shell.execute_reply.started":"2025-09-13T18:44:20.133692Z","shell.execute_reply":"2025-09-13T18:44:23.281046Z"}},"outputs":[{"name":"stdout","text":"Full training data:  (1001343, 24)\nFull training data columns:  ['file_name', 'image_shape', 'coordinates_x', 'coordinates_y', 'coordinates_f', 'aneurysm_present_in_series', 'aneurysm_present_in_image', 'seriesinstanceuid', 'patientage', 'patientsex', 'modality', 'left_infraclinoid_internal_carotid_artery', 'right_infraclinoid_internal_carotid_artery', 'left_supraclinoid_internal_carotid_artery', 'right_supraclinoid_internal_carotid_artery', 'left_middle_cerebral_artery', 'right_middle_cerebral_artery', 'anterior_communicating_artery', 'left_anterior_cerebral_artery', 'right_anterior_cerebral_artery', 'left_posterior_communicating_artery', 'right_posterior_communicating_artery', 'basilar_tip', 'other_posterior_circulation']\nAneurysm not present in 999094 series\nAneurysm present in 2249 series\nAneurysm not shown in 999094 images\nAneurysm shown in 2249 images\nshape: (9, 3)\n┌────────────┬───────────────┬───────────────┐\n│ statistic  ┆ coordinates_x ┆ coordinates_y │\n│ ---        ┆ ---           ┆ ---           │\n│ str        ┆ f64           ┆ f64           │\n╞════════════╪═══════════════╪═══════════════╡\n│ count      ┆ 2249.0        ┆ 2249.0        │\n│ null_count ┆ 999094.0      ┆ 999094.0      │\n│ mean       ┆ 252.214621    ┆ 215.838476    │\n│ std        ┆ 66.245059     ┆ 52.336721     │\n│ min        ┆ 49.731607     ┆ 76.031551     │\n│ 25%        ┆ 220.207492    ┆ 190.429365    │\n│ 50%        ┆ 253.648748    ┆ 210.499102    │\n│ 75%        ┆ 280.259615    ┆ 232.156863    │\n│ max        ┆ 714.748844    ┆ 583.68        │\n└────────────┴───────────────┴───────────────┘\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"df_all_data.write_parquet('full_training_data.parquet')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Looking at a specific CTA image that shows aneurysm\n## Taking a multi-frame image by converting it to single-frame image","metadata":{}},{"cell_type":"code","source":"df_all_data = pl.read_parquet('/kaggle/input/rsna-aneurysm-train-metadata-suman/full_training_data.parquet')\nprint(\"Shape of training metadata\", df_all_data.shape)\ndf_all_data.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:48:43.82027Z","iopub.execute_input":"2025-09-05T19:48:43.820589Z","iopub.status.idle":"2025-09-05T19:48:44.147877Z","shell.execute_reply.started":"2025-09-05T19:48:43.820563Z","shell.execute_reply":"2025-09-05T19:48:44.143024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"root_folder = \"/kaggle/input/rsna-intracranial-aneurysm-detection/series\"\n\ndef create_full_image_path(row_data):\n    return row_data['root_folder'] + '/' + row_data['seriesinstanceuid'] + '/' + row_data['file_name']\n\ndf_all_data = df_all_data.with_columns(pl.lit(root_folder).alias(\"root_folder\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:48:47.132372Z","iopub.execute_input":"2025-09-05T19:48:47.132737Z","iopub.status.idle":"2025-09-05T19:48:47.157229Z","shell.execute_reply.started":"2025-09-05T19:48:47.132708Z","shell.execute_reply":"2025-09-05T19:48:47.151839Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_all_data = df_all_data.with_columns([\n    pl.struct(pl.col(\"root_folder\"), pl.col(\"seriesinstanceuid\"), pl.col(\"file_name\"))\n    .map_elements(create_full_image_path, return_dtype=pl.String)\n    #.cast(pl.String)\n    .alias(\"full_image_path\")\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:48:51.664226Z","iopub.execute_input":"2025-09-05T19:48:51.664589Z","iopub.status.idle":"2025-09-05T19:48:55.905106Z","shell.execute_reply.started":"2025-09-05T19:48:51.66456Z","shell.execute_reply":"2025-09-05T19:48:55.900296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_all_data.filter(\n    (pl.col('coordinates_x').is_not_null())\n    &\n    (pl.col('coordinates_f') == 0)\n).head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_all_data.filter(\n    (pl.col('coordinates_x').is_not_null())\n    &\n    (pl.col('coordinates_f') != 0)\n).head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_all_data.filter(\n    (pl.col('coordinates_x').is_not_null())\n    &\n    (pl.col('coordinates_f') != 0)\n).select(pl.col('full_image_path')).count()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_single_frame(multiframe_path, slice_number, output_path=None):\n    \"\"\"\n    Extract a single frame from a multi-frame DICOM\n    \n    Args:\n        multiframe_path: Path to multi-frame DICOM file\n        slice_number: The slice number to extract (0-based index)\n        output_path: Path to save the single-frame DICOM. If None, returns the dataset\n    \"\"\"\n    try:\n        # Read the multi-frame DICOM with force=True to handle potentially corrupted files\n        multi_ds = dcmread(multiframe_path, force=True)\n        \n        # Verify it's a multi-frame image\n        if not hasattr(multi_ds, 'NumberOfFrames'):\n            raise ValueError(\"Input DICOM is not a multi-frame image\")\n        \n        # Check if slice number is valid\n        if slice_number >= multi_ds.NumberOfFrames:\n            raise ValueError(f\"Slice number {slice_number} is out of range. \"\n                           f\"Image has {multi_ds.NumberOfFrames} frames\")\n        \n        # Create new dataset for single frame\n        single_ds = FileDataset(output_path or \"temp.dcm\", {}, \n                              file_meta=FileMetaDataset(), \n                              preamble=b\"\\0\" * 128)\n        \n        # Copy attributes from multi-frame dataset\n        attrs_to_copy = allowed_tags\n        \n        for attr in attrs_to_copy:\n            if hasattr(multi_ds, attr):\n                setattr(single_ds, attr, getattr(multi_ds, attr))\n        \n        # Generate new UIDs\n        single_ds.SOPInstanceUID = generate_uid()\n        single_ds.file_meta.MediaStorageSOPInstanceUID = single_ds.SOPInstanceUID\n        \n        # Set transfer syntax to uncompressed little endian\n        single_ds.file_meta.TransferSyntaxUID = ImplicitVRLittleEndian\n        single_ds.file_meta.MediaStorageSOPClassUID = multi_ds.file_meta.MediaStorageSOPClassUID\n        if hasattr(multi_ds.file_meta, 'ImplementationClassUID'):\n            single_ds.file_meta.ImplementationClassUID = multi_ds.file_meta.ImplementationClassUID\n        \n        # Set instance-specific attributes\n        single_ds.InstanceNumber = slice_number + 1\n        \n        try:\n            # Try to get pixel array directly\n            pixel_array = multi_ds.pixel_array[slice_number]\n        except Exception as e:\n            #print(f\"Warning: Could not directly access pixel_array: {e}\")\n            # Alternative approach: decompress and get pixels\n            if hasattr(multi_ds, 'decompress'):\n                multi_ds.decompress()\n            pixel_array = multi_ds.pixel_array[slice_number]\n        \n        # Set pixel data\n        single_ds.PixelData = pixel_array.tobytes()\n        \n        # Update image-specific attributes\n        single_ds.NumberOfFrames = 1\n        \n        # Try to copy position and orientation\n        try:\n            if hasattr(multi_ds, 'PerFrameFunctionalGroupsSequence'):\n                frame_content = multi_ds.PerFrameFunctionalGroupsSequence[slice_number]\n                \n                if hasattr(frame_content, 'PlanePositionSequence'):\n                    position = frame_content.PlanePositionSequence[0].ImagePositionPatient\n                    single_ds.ImagePositionPatient = position\n                \n                if hasattr(frame_content, 'PlaneOrientationSequence'):\n                    orientation = frame_content.PlaneOrientationSequence[0].ImageOrientationPatient\n                    single_ds.ImageOrientationPatient = orientation\n        except Exception as e:\n            #print(f\"Warning: Could not copy position/orientation: {e}\")\n            raise\n        \n        # Add creation timestamp\n        dt = datetime.datetime.now()\n        single_ds.ContentDate = dt.strftime('%Y%m%d')\n        single_ds.ContentTime = dt.strftime('%H%M%S.%f')\n        \n        # Save or return the dataset\n        if output_path:\n            single_ds.save_as(output_path, write_like_original=False)\n            return None\n        return single_ds\n    \n    except Exception as e:\n        #print(f\"Error extracting frame: {e}\")\n        raise\n\n# Alternative version using different approach for compressed files\ndef extract_single_frame_alternative(multiframe_path, slice_number, output_path=None):\n    \"\"\"\n    Alternative version for handling problematic files\n    \"\"\"\n    try:\n        # Read with force and stop before pixels\n        multi_ds = dcmread(multiframe_path, force=True, stop_before_pixels=True)\n        \n        # Read pixel data separately\n        with open(multiframe_path, 'rb') as f:\n            multi_ds.PixelData = f.read()\n        \n        # Decompress if needed\n        if hasattr(multi_ds, 'decompress'):\n            multi_ds.decompress()\n        \n        # Get pixel array\n        pixel_array = multi_ds.pixel_array[slice_number]\n        \n        # Create new dataset\n        single_ds = FileDataset(output_path or \"temp.dcm\", {}, \n                              file_meta=FileMetaDataset(), \n                              preamble=b\"\\0\" * 128)\n        \n        # Copy attributes (same as before)\n        attrs_to_copy = allowed_tags\n        \n        for attr in attrs_to_copy:\n            if hasattr(multi_ds, attr):\n                setattr(single_ds, attr, getattr(multi_ds, attr))\n        \n        # Generate new UIDs\n        single_ds.SOPInstanceUID = generate_uid()\n        single_ds.file_meta.MediaStorageSOPInstanceUID = single_ds.SOPInstanceUID\n        \n        # Set transfer syntax to uncompressed little endian\n        single_ds.file_meta.TransferSyntaxUID = ImplicitVRLittleEndian\n        single_ds.file_meta.MediaStorageSOPClassUID = multi_ds.file_meta.MediaStorageSOPClassUID\n        if hasattr(multi_ds.file_meta, 'ImplementationClassUID'):\n            single_ds.file_meta.ImplementationClassUID = multi_ds.file_meta.ImplementationClassUID\n        \n        # Set instance-specific attributes\n        single_ds.InstanceNumber = slice_number + 1\n        \n        try:\n            # Try to get pixel array directly\n            pixel_array = multi_ds.pixel_array[slice_number]\n        except Exception as e:\n            #print(f\"Warning: Could not directly access pixel_array: {e}\")\n            # Alternative approach: decompress and get pixels\n            if hasattr(multi_ds, 'decompress'):\n                multi_ds.decompress()\n            pixel_array = multi_ds.pixel_array[slice_number]\n        \n        # Set pixel data\n        single_ds.PixelData = pixel_array.tobytes()\n        \n        # Update image-specific attributes\n        single_ds.NumberOfFrames = 1\n        \n        # Try to copy position and orientation\n        try:\n            if hasattr(multi_ds, 'PerFrameFunctionalGroupsSequence'):\n                frame_content = multi_ds.PerFrameFunctionalGroupsSequence[slice_number]\n                \n                if hasattr(frame_content, 'PlanePositionSequence'):\n                    position = frame_content.PlanePositionSequence[0].ImagePositionPatient\n                    single_ds.ImagePositionPatient = position\n                \n                if hasattr(frame_content, 'PlaneOrientationSequence'):\n                    orientation = frame_content.PlaneOrientationSequence[0].ImageOrientationPatient\n                    single_ds.ImageOrientationPatient = orientation\n        except Exception as e:\n            #print(f\"Warning: Could not copy position/orientation: {e}\")\n            raise\n        \n        # Add creation timestamp\n        dt = datetime.datetime.now()\n        single_ds.ContentDate = dt.strftime('%Y%m%d')\n        single_ds.ContentTime = dt.strftime('%H%M%S.%f')\n        \n        # Save or return the dataset\n        if output_path:\n            single_ds.save_as(output_path, write_like_original=False)\n            return None\n        return single_ds\n        \n    except Exception as e:\n        #print(f\"Error in alternative extraction: {e}\")\n        raise\n\n# Function to try both methods\ndef safe_extract_single_frame(multiframe_path, slice_number, output_path=None):\n    \"\"\"\n    Try both extraction methods\n    \"\"\"\n    try:\n        return extract_single_frame(multiframe_path, slice_number, output_path)\n    except Exception as e:\n        #print(f\"Primary method failed: {e}\")\n        #print(\"Trying alternative method...\")\n        try:\n            return extract_single_frame_alternative(multiframe_path, slice_number, output_path)\n        except Exception as e2:\n            #print(f\"Alternative method also failed: {e2}\")\n            raise\n\n# Version with zoom functionality\ndef load_and_view_single_slice_with_zoom(dcm_path, x_coord, y_coord, f_coord=None, zoom_size=100):\n    \"\"\"\n    Load and display a single DICOM slice with crosshair and zoomed inset\n    \n    Args:\n        dcm_path: Path to the DICOM file\n        x_coord: x coordinate for the crosshair\n        y_coord: y coordinate for the crosshair\n        zoom_size: Size of the zoom window in pixels\n    \"\"\"\n    # Read DICOM file\n    if f_coord:\n        ds = safe_extract_single_frame(dcm_path, f_coord)\n    else:\n        ds = dcmread(dcm_path)\n    img = ds.pixel_array\n    \n    # Create figure and axes\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n    \n    # Main image with crosshair\n    ax1.imshow(img, cmap='gray')\n    ax1.axvline(x=x_coord, color='red', alpha=0.5)\n    ax1.axhline(y=y_coord, color='red', alpha=0.5)\n    ax1.plot(x_coord, y_coord, 'r+', markersize=10, markeredgewidth=2)\n    \n    # Zoomed region\n    x_start = int(max(0, x_coord - zoom_size/2))\n    x_end = int(min(img.shape[1], x_coord + zoom_size/2))\n    y_start = int(max(0, y_coord - zoom_size/2))\n    y_end = int(min(img.shape[0], y_coord + zoom_size/2))\n    \n    zoomed = img[y_start:y_end, x_start:x_end]\n    ax2.imshow(zoomed, cmap='gray')\n    \n    # Add crosshair to zoomed region\n    center_x = x_coord - x_start\n    center_y = y_coord - y_start\n    ax2.axvline(x=center_x, color='red', alpha=0.5)\n    ax2.axhline(y=center_y, color='red', alpha=0.5)\n    ax2.plot(center_x, center_y, 'r+', markersize=10, markeredgewidth=2)\n    \n    ax1.axis('off')\n    ax2.axis('off')\n    ax1.set_title('Full Image')\n    ax2.set_title('Zoomed Region')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T20:02:22.496758Z","iopub.execute_input":"2025-09-05T20:02:22.497145Z","iopub.status.idle":"2025-09-05T20:02:22.526777Z","shell.execute_reply.started":"2025-09-05T20:02:22.497116Z","shell.execute_reply":"2025-09-05T20:02:22.522338Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"dcm_path = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10656705618563493995266564048457485210/1.2.826.0.1.3680043.8.498.42869495026349479137655237867466396964.dcm'\nx_coord = 297.728962\ny_coord = 209.570827\nf_coord = 65\nload_and_view_single_slice_with_zoom(dcm_path, x_coord, y_coord, f_coord)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dcm_path = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10602156717395509282545203380100998253/1.2.826.0.1.3680043.8.498.50109132199445951854133683565774892169.dcm'\nx_coord = 256.300637\ny_coord = 146.099363\nload_and_view_single_slice_with_zoom(dcm_path, x_coord, y_coord, f_coord)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if f_coord:\n    ds = safe_extract_single_frame(dcm_path, f_coord)\nelse:\n    ds = dcmread(dcm_path)\n\narr = ds.pixel_array.astype(np.float32)\n\n# Apply rescale if present\nslope = float(getattr(ds, \"RescaleSlope\", 1) or 1)\nintercept = float(getattr(ds, \"RescaleIntercept\", 0) or 0)\narr = arr * slope + intercept\n\n# Handle MONOCHROME1 (invert)\nif getattr(ds, \"PhotometricInterpretation\", \"\") == \"MONOCHROME1\":\n    arr = arr.max() - arr\n\nimage = tf.convert_to_tensor(arr)\n\nexpanded_image = tf.expand_dims(image, -1)\nm, M=tf.math.reduce_min(expanded_image), tf.math.reduce_max(expanded_image)\nexpanded_image = (tf.image.grayscale_to_rgb(expanded_image)-m)/(M-m)\nexpanded_image = tf.image.resize(expanded_image, (128,128))\nsqzd_image = tf.squeeze(expanded_image)\n\ntrain_img = tf.reshape(sqzd_image, shape=(128, 128, 3))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_np = train_img.numpy()\nplt.imshow(image_np)\nplt.title(\"TensorFlow Image Visualization\")\nplt.axis('off') # Hide axes for cleaner image display\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_and_parse_dicom_files_tensorflow_train(dcm_path, f_coord):\n    if f_coord:\n        ds = safe_extract_single_frame(dcm_path, f_coord)\n    else:\n        ds = dcmread(dcm_path)\n    \n    arr = ds.pixel_array.astype(np.float32)\n    \n    # Apply rescale if present\n    slope = float(getattr(ds, \"RescaleSlope\", 1) or 1)\n    intercept = float(getattr(ds, \"RescaleIntercept\", 0) or 0)\n    arr = arr * slope + intercept\n    \n    # Handle MONOCHROME1 (invert)\n    if getattr(ds, \"PhotometricInterpretation\", \"\") == \"MONOCHROME1\":\n        arr = arr.max() - arr\n    \n    image = tf.convert_to_tensor(arr)\n    \n    expanded_image = tf.expand_dims(image, -1)\n    m, M=tf.math.reduce_min(expanded_image), tf.math.reduce_max(expanded_image)\n    expanded_image = (tf.image.grayscale_to_rgb(expanded_image)-m)/(M-m)\n    expanded_image = tf.image.resize(expanded_image, (128,128))\n    sqzd_image = tf.squeeze(expanded_image)\n\n    return sqzd_image\n\ndef preprocessing(dcm_path, f_coord):\n    train_img = read_and_parse_dicom_files_tensorflow_train(dcm_path, f_coord)\n    train_img = tf.reshape(train_img, shape=(128, 128, 3))\n    return train_img\n\ndef load_dataset_tensorflow_train(dcm_path, f_coord, labels):\n    image = preprocessing(dcm_path, f_coord)\n    return {\"images\": tf.cast(image, tf.float32), \"labels\": tf.cast(labels, tf.float32)}\n\ndef dict_to_tuple(inputs):\n    return inputs[\"images\"], inputs[\"labels\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T20:02:30.984843Z","iopub.execute_input":"2025-09-05T20:02:30.985267Z","iopub.status.idle":"2025-09-05T20:02:31.000289Z","shell.execute_reply.started":"2025-09-05T20:02:30.985238Z","shell.execute_reply":"2025-09-05T20:02:30.995422Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"df_all_data.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:49:18.216715Z","iopub.execute_input":"2025-09-05T19:49:18.21707Z","iopub.status.idle":"2025-09-05T19:49:18.231618Z","shell.execute_reply.started":"2025-09-05T19:49:18.217042Z","shell.execute_reply":"2025-09-05T19:49:18.22668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols_to_select = ['full_image_path', 'left_infraclinoid_internal_carotid_artery',  'right_infraclinoid_internal_carotid_artery',  'left_supraclinoid_internal_carotid_artery'\n                  ,  'right_supraclinoid_internal_carotid_artery',  'left_middle_cerebral_artery',  'right_middle_cerebral_artery',  'anterior_communicating_artery'\n                  ,  'left_anterior_cerebral_artery',  'right_anterior_cerebral_artery',  'left_posterior_communicating_artery',  'right_posterior_communicating_artery'\n                  ,  'basilar_tip',  'other_posterior_circulation'\n]\n\ndf_for_train_baseline = df_all_data.select(cols_to_select)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T20:02:35.138893Z","iopub.execute_input":"2025-09-05T20:02:35.139233Z","iopub.status.idle":"2025-09-05T20:02:35.151178Z","shell.execute_reply.started":"2025-09-05T20:02:35.139206Z","shell.execute_reply":"2025-09-05T20:02:35.145111Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"x_train, x_test_val = train_test_split(df_for_train_baseline, test_size=0.4, random_state=42)\nx_test, x_valid = train_test_split(x_test_val, test_size=0.2, random_state=42)\n\nprint(\"Training data shape : {0}\".format(x_train.shape))\nprint(\"Test data shape : {0}\".format(x_test.shape))\nprint(\"Validation data shape : {0}\".format(x_valid.shape))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T20:02:39.328407Z","iopub.execute_input":"2025-09-05T20:02:39.328792Z","iopub.status.idle":"2025-09-05T20:02:39.658796Z","shell.execute_reply.started":"2025-09-05T20:02:39.328762Z","shell.execute_reply":"2025-09-05T20:02:39.655097Z"}},"outputs":[{"name":"stdout","text":"Training data shape : (600807, 14)\nTest data shape : (320431, 14)\nValidation data shape : (80108, 14)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"label_cols = ['left_infraclinoid_internal_carotid_artery',  'right_infraclinoid_internal_carotid_artery',  'left_supraclinoid_internal_carotid_artery'\n                  ,  'right_supraclinoid_internal_carotid_artery',  'left_middle_cerebral_artery',  'right_middle_cerebral_artery',  'anterior_communicating_artery'\n                  ,  'left_anterior_cerebral_artery',  'right_anterior_cerebral_artery',  'left_posterior_communicating_artery',  'right_posterior_communicating_artery'\n                  ,  'basilar_tip',  'other_posterior_circulation'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T20:02:42.380596Z","iopub.execute_input":"2025-09-05T20:02:42.380929Z","iopub.status.idle":"2025-09-05T20:02:42.3924Z","shell.execute_reply.started":"2025-09-05T20:02:42.380903Z","shell.execute_reply":"2025-09-05T20:02:42.386474Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"#### This is a multi-label classification problem where each instance (i.e. each DICOM image) can be labelled with at-most 13 labels (i.e. brain locations).\n#### The resulting predictions will then need to be aggregated up at the level of each scan series\n#### Finally the main target variable has to be calculated as the max of all the 13 labels, i.e. if at least one of the 13 labels is 1 then the final target variable is 1","metadata":{}},{"cell_type":"code","source":"tpu_strategy.num_replicas_in_sync","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T20:02:45.03634Z","iopub.execute_input":"2025-09-05T20:02:45.036722Z","iopub.status.idle":"2025-09-05T20:02:45.052489Z","shell.execute_reply.started":"2025-09-05T20:02:45.036695Z","shell.execute_reply":"2025-09-05T20:02:45.047633Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"8"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"def generate_tf_datasets(p_df, p_BATCH_SIZE_PER_REPLICA):\n\n    BATCH_SIZE = p_BATCH_SIZE_PER_REPLICA * tpu_strategy.num_replicas_in_sync\n    \n    image_filenames = pl.Series(p_df.select(pl.col('full_image_path'))).to_list()\n    image_labels = pl.Series(p_df.select(label_cols)).to_list()\n    \n    image_dataset = tf.data.Dataset.from_tensor_slices((image_filenames, image_labels))\n    \n    image_ds = image_dataset.map(load_dataset_tensorflow_train, num_parallel_calls=tf.data.AUTOTUNE)\n    image_ds = image_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n    image_ds = image_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n    image_ds = image_ds.prefetch(tf.data.AUTOTUNE)\n    \n    return image_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T20:02:47.757738Z","iopub.execute_input":"2025-09-05T20:02:47.758102Z","iopub.status.idle":"2025-09-05T20:02:47.77067Z","shell.execute_reply.started":"2025-09-05T20:02:47.758072Z","shell.execute_reply":"2025-09-05T20:02:47.764887Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"train_ds = generate_tf_datasets(p_df=x_train, p_BATCH_SIZE_PER_REPLICA = 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T20:02:50.308973Z","iopub.execute_input":"2025-09-05T20:02:50.309345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(train_ds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}