{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceType":"competition","sourceId":99552,"databundleVersionId":13441085},{"sourceType":"datasetVersion","sourceId":8236972,"datasetId":4885707,"databundleVersionId":8363934},{"sourceType":"datasetVersion","sourceId":12850999,"datasetId":8127880,"databundleVersionId":13488720}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sumaniitm/complete-train-metadata-using-duckdb-and-polars?scriptVersionId=260193240\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Installing required dependencies","metadata":{}},{"cell_type":"code","source":"!pip install duckdb --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\n!pip install python-gdcm\n!pip install pylibjpeg\n!pip install pylibjpeg-libjpeg==2.2.0\n!pip install pylibjpeg-openjpeg==2.3.0\n!pip install matplotlib==3.10.3\n!pip install scikit-learn==1.7.0\n!pip install polars --no-index --find-links=/kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\n!pip install pydicom","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:47:07.735934Z","iopub.execute_input":"2025-09-05T19:47:07.736309Z","iopub.status.idle":"2025-09-05T19:47:39.51336Z","shell.execute_reply.started":"2025-09-05T19:47:07.736276Z","shell.execute_reply":"2025-09-05T19:47:39.507326Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/duck_pkg\nRequirement already satisfied: duckdb in /usr/local/lib/python3.10/site-packages (0.8.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: python-gdcm in /usr/local/lib/python3.10/site-packages (3.0.26)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: pylibjpeg in /usr/local/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from pylibjpeg) (2.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: pylibjpeg-libjpeg==2.2.0 in /usr/local/lib/python3.10/site-packages (2.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from pylibjpeg-libjpeg==2.2.0) (2.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: pylibjpeg-openjpeg==2.3.0 in /usr/local/lib/python3.10/site-packages (2.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from pylibjpeg-openjpeg==2.3.0) (2.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: matplotlib==3.10.3 in /usr/local/lib/python3.10/site-packages (3.10.3)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (25.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (3.2.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (1.3.2)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (2.9.0.post0)\nRequirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (2.0.2)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (4.58.4)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (1.4.8)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib==3.10.3) (11.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.10.3) (1.17.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: scikit-learn==1.7.0 in /usr/local/lib/python3.10/site-packages (1.7.0)\nRequirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.7.0) (1.15.3)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.7.0) (1.5.1)\nRequirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.7.0) (2.0.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn==1.7.0) (3.6.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nLooking in links: /kaggle/input/polars-and-duckdb/kaggle/working/mysitepackages/polars_pkg\nRequirement already satisfied: polars in /usr/local/lib/python3.10/site-packages (0.20.16)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: pydicom in /usr/local/lib/python3.10/site-packages (3.0.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Importing required libraries","metadata":{}},{"cell_type":"code","source":"from pydicom import dcmread\nfrom pydicom.dataset import FileDataset, FileMetaDataset\nfrom pydicom.uid import generate_uid, ImplicitVRLittleEndian\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport polars as pl\nimport duckdb as dd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport cv2\nimport pickle\nimport gc\nimport ctypes\nfrom pathlib import Path\nimport logging\nimport json\nimport multiprocessing as mp\nfrom concurrent.futures import ProcessPoolExecutor\nimport datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import log_loss\nimport tensorflow as tf\nimport tensorflow_io as tfio\nfrom tensorflow import keras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:47:43.547161Z","iopub.execute_input":"2025-09-05T19:47:43.547511Z","iopub.status.idle":"2025-09-05T19:47:47.913896Z","shell.execute_reply.started":"2025-09-05T19:47:43.54748Z","shell.execute_reply":"2025-09-05T19:47:47.909925Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1757101665.781586    2091 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:230\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(tf.__version__)\nprint(tfio.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Initializing the TPU","metadata":{}},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)\n\nprint(\"Number of accelerators: \", tpu_strategy.num_replicas_in_sync)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:48:05.29007Z","iopub.execute_input":"2025-09-05T19:48:05.290638Z","iopub.status.idle":"2025-09-05T19:48:12.96841Z","shell.execute_reply.started":"2025-09-05T19:48:05.290606Z","shell.execute_reply":"2025-09-05T19:48:12.963541Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1757101687.938904    2091 service.cc:148] XLA service 0x57f75d748d50 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1757101687.938951    2091 service.cc:156]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1757101687.938955    2091 service.cc:156]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1757101687.938958    2091 service.cc:156]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1757101687.938960    2091 service.cc:156]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1757101687.938963    2091 service.cc:156]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1757101687.938966    2091 service.cc:156]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1757101687.938968    2091 service.cc:156]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1757101687.938971    2091 service.cc:156]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\nNumber of accelerators:  8\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Setting polars configs to view the dataframes better","metadata":{}},{"cell_type":"code","source":"pl.Config(fmt_str_lengths=1000)\npl.Config.set_tbl_rows(1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:48:28.454399Z","iopub.execute_input":"2025-09-05T19:48:28.454745Z","iopub.status.idle":"2025-09-05T19:48:28.471481Z","shell.execute_reply.started":"2025-09-05T19:48:28.454718Z","shell.execute_reply":"2025-09-05T19:48:28.465613Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"polars.config.Config"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Load the metadata of the training images\n## Also separate out the localizer coordinates into individual columns","metadata":{}},{"cell_type":"code","source":"train_meta_data = pl.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train.csv'\\\n                              , low_memory=True)\n\ntrain_locale_meta_data = pl.read_csv('/kaggle/input/rsna-intracranial-aneurysm-detection/train_localizers.csv'\\\n                              , low_memory=True)\n\ndef parse_coordinates(coord_str):\n    if coord_str is None:\n        return None, None\n    try:\n        coord_dict = json.loads(coord_str.replace(\"'\", '\"'))\n        return float(coord_dict.get('x', 0.0)), float(coord_dict.get('y', 0.0)), int(coord_dict.get('f', 0.0))\n    except (json.JSONDecodeError, KeyError, ValueError, AttributeError):\n        return None, None\n\ntrain_locale_meta_data = train_locale_meta_data.with_columns([\n    pl.col(\"coordinates\")\n    .map_elements(lambda x: parse_coordinates(x)[0], return_dtype=pl.Float64)\n    .cast(pl.Float64)\n    .alias(\"coordinates_x\"),\n    \n    pl.col(\"coordinates\")\n    .map_elements(lambda x: parse_coordinates(x)[1], return_dtype=pl.Float64)\n    .cast(pl.Float64)\n    .alias(\"coordinates_y\"),\n    \n    pl.col(\"coordinates\")\n    .map_elements(lambda x: parse_coordinates(x)[2], return_dtype=pl.Int32)\n    .cast(pl.Int32)\n    .alias(\"coordinates_f\")\n])\n\nprint(\"Train CSV shape : \", train_meta_data.shape)\nprint(\"Train Localizers CSV shape : \", train_locale_meta_data.shape)\n# Show the first few rows\nprint(train_locale_meta_data.filter(pl.col('coordinates_f') != 0.0)\\\n      .select([\"coordinates\", \"coordinates_x\", \"coordinates_y\", \"coordinates_f\"]).head(5))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Glancing at the datasets so far","metadata":{}},{"cell_type":"code","source":"train_meta_data.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_locale_meta_data.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Get summary statistics of the new columns","metadata":{}},{"cell_type":"code","source":"print(train_locale_meta_data.select([\"coordinates_x\", \"coordinates_y\", \"coordinates_f\"]).describe())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Get the image metadata from each training series and create a dataframe out of them","metadata":{}},{"cell_type":"code","source":"allowed_tags = ['BitsAllocated', 'BitsStored', 'Rows', 'Columns', 'FrameOfReferenceUID', 'HighBit', 'ImageOrientationPatient'\n                , 'ImagePositionPatient', 'InstanceNumber', 'Modality', 'PhotometricInterpretation'\n                , 'PixelRepresentation', 'PixelSpacing', 'PlanarConfiguration', 'RescaleIntercept', 'RescaleSlope'\n                , 'RescaleType', 'SamplesPerPixel', 'SliceThickness', 'SpacingBetweenSlices']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:48:33.416199Z","iopub.execute_input":"2025-09-05T19:48:33.416509Z","iopub.status.idle":"2025-09-05T19:48:33.426667Z","shell.execute_reply.started":"2025-09-05T19:48:33.416483Z","shell.execute_reply":"2025-09-05T19:48:33.421633Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Functions to collect metadata without the image arrays\n### We use python slots to reduce the memory foorprint\n### Also use multithreading to speed up processing","metadata":{}},{"cell_type":"code","source":"class DicomRecord:\n    \"\"\"\n    Memory-efficient class for storing DICOM metadata using __slots__\n    \"\"\"\n    __slots__ = ['folder_name', 'file_name', 'file_path', 'image_shape'] + [\n        'BitsAllocated', 'BitsStored', 'Rows', 'Columns', 'FrameOfReferenceUID',\n        'HighBit', 'ImageOrientationPatient', 'ImagePositionPatient', 'InstanceNumber',\n        'Modality', 'PhotometricInterpretation', 'PixelRepresentation', 'PixelSpacing',\n        'PlanarConfiguration', 'RescaleIntercept', 'RescaleSlope', 'RescaleType',\n        'SamplesPerPixel', 'SliceThickness', 'SpacingBetweenSlices'\n    ]\n    \n    def __init__(self, folder_name, file_name, file_path, image_shape):\n        self.folder_name = folder_name\n        self.file_name = file_name\n        self.file_path = file_path\n        self.image_shape = image_shape\n        for tag in self.__slots__[4:]:  \n            setattr(self, tag, None)\n    \n    def to_dict(self):\n        return {slot: getattr(self, slot) for slot in self.__slots__}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_single_folder(folder_path, allowed_tags):\n    \"\"\"\n    Process a single folder of DICOM files and save image arrays\n    \"\"\"\n    try:\n        data = []\n        dcm_files = list(Path(folder_path).glob(\"*.dcm\"))\n        folder_name = Path(folder_path).name\n        \n        for dcm_file in dcm_files:\n            try:\n                # Read DICOM file\n                ds = dcmread(str(dcm_file))\n                original_shape = str(ds.pixel_array.shape)\n                \n                # Create record\n                record = DicomRecord(folder_name, dcm_file.name, str(dcm_file), original_shape)\n                \n                # Fill in tags\n                for tag in allowed_tags:\n                    try:\n                        value = getattr(ds, tag)\n                        if hasattr(value, '__iter__') and not isinstance(value, str):\n                            value = str(list(map(str, value)))\n                        else:\n                            value = str(value)\n                        setattr(record, tag, value)\n                    except (AttributeError, TypeError):\n                        continue\n                \n                data.append(record.to_dict())\n                \n            except Exception as e:\n                print(f\"Error processing file {dcm_file}: {e}\")\n                continue\n                \n        return data\n        \n    except Exception as e:\n        print(f\"Error processing folder {folder_path}: {e}\")\n        return []","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_dicom_dataset(root_folder, allowed_tags, num_processes=None, chunk_size=100):\n    \"\"\"\n    Create dataset with metadata DataFrame and memory-mapped image arrays\n    \"\"\"\n    root_path = Path(root_folder)\n    folders = [f for f in root_path.iterdir() if f.is_dir()]\n    \n    if not num_processes:\n        num_processes = mp.cpu_count()\n    \n    # Create directories for temporary and array storage\n    temp_dir = Path(\"temp_chunks\")\n    temp_dir.mkdir(exist_ok=True)\n    \n    # Create schema\n    schema = {\n        'folder_name': pl.Utf8,\n        'file_name': pl.Utf8,\n        'file_path': pl.String,\n        'image_shape': pl.String\n    }\n    schema.update({tag: pl.Utf8 for tag in allowed_tags})\n    \n    # Process folders in parallel\n    with ProcessPoolExecutor(max_workers=num_processes) as executor:\n        for i in range(0, len(folders), chunk_size):\n            chunk_folders = folders[i:i+chunk_size]\n            chunk_data = []\n            \n            futures = [\n                executor.submit(\n                    process_single_folder, \n                    str(folder), \n                    allowed_tags\n                    #arrays_dir\n                )\n                for folder in chunk_folders\n            ]\n            \n            for future in tqdm(futures, \n                             desc=f\"Processing chunk {i//chunk_size + 1}/{(len(folders)-1)//chunk_size + 1}\"):\n                chunk_data.extend(future.result())\n            \n            if chunk_data:\n                chunk_df = pl.DataFrame(\n                    chunk_data,\n                    schema=schema,\n                    infer_schema_length=None\n                )\n                \n                chunk_df.write_parquet(\n                    temp_dir / f\"dicom_metadata_chunk_{i//chunk_size}.parquet\",\n                    compression=\"snappy\"\n                )\n                \n                del chunk_data\n                del chunk_df\n    \n    # Combine chunks\n    print(\"\\nCombining chunks...\")\n    chunk_files = list(temp_dir.glob(\"dicom_metadata_chunk_*.parquet\"))\n    final_df = pl.concat([\n        pl.scan_parquet(str(chunk_file))\n        for chunk_file in chunk_files\n    ]).collect()\n    \n    # Clean up temporary files\n    for f in chunk_files:\n        f.unlink()\n    temp_dir.rmdir()\n    \n    return final_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Starting the collection of metadata","metadata":{}},{"cell_type":"code","source":"with tpu_strategy.scope():\n    root_folder = \"/kaggle/input/rsna-intracranial-aneurysm-detection/series\"\n    \n    try:\n        metadata_df = create_dicom_dataset(\n            root_folder, \n            allowed_tags, \n            num_processes=mp.cpu_count(),\n            chunk_size=192\n        )\n    except Exception as e:\n        print(f\"Error: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metadata_df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create the full training data\n* Bring in the localizer coordinates for the series where aneurysm is present\n* Create another column to signify whether aneurysm is shown in a specific image within a series\n* There can be cases where some images of a series cannot catch aneurysm presence\n* Bringing all the rows at the image file granularity, i.e. if a file has coordinates then it has aneurysm else not","metadata":{}},{"cell_type":"code","source":"df_all_coordinates = dd.sql( \\\n    \"select t2.coordinates_x, t2.coordinates_y, t2.coordinates_f, t1.* \\\n    from metadata_df t1 \\\n    left join train_locale_meta_data t2 \\\n    on t1.folder_name = t2.SeriesInstanceUID \\\n    and replace(t1.file_name, '.dcm','') = t2.SOPInstanceUID \"\\\n).pl()\n\nprint(df_all_coordinates.shape)\nprint(df_all_coordinates.columns)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_all_data = dd.sql( \\\n    \"select t2.file_name, t2.image_shape, t2.coordinates_x, t2.coordinates_y, t2.coordinates_f \\\n    , t1.aneurysm_present as aneurysm_present_in_series \\\n    , case when t2.coordinates_x is not null then 1 else 0 end as aneurysm_present_in_image \\\n    , t1.seriesinstanceuid, t1.patientage, t1.patientsex, t1.modality \\\n    , case when t2.coordinates_x is not null then t1.left_infraclinoid_internal_carotid_artery \\\n    else 0 end as left_infraclinoid_internal_carotid_artery \\\n    , case when t2.coordinates_x is not null then t1.right_infraclinoid_internal_carotid_artery \\\n    else 0 end as right_infraclinoid_internal_carotid_artery \\\n    , case when t2.coordinates_x is not null then t1.left_supraclinoid_internal_carotid_artery \\\n    else 0 end as left_supraclinoid_internal_carotid_artery \\\n    , case when t2.coordinates_x is not null then t1.right_supraclinoid_internal_carotid_artery \\\n    else 0 end as right_supraclinoid_internal_carotid_artery \\\n    , case when t2.coordinates_x is not null then t1.left_middle_cerebral_artery \\\n    else 0 end as left_middle_cerebral_artery \\\n    , case when t2.coordinates_x is not null then t1.right_middle_cerebral_artery \\\n    else 0 end as right_middle_cerebral_artery \\\n    , case when t2.coordinates_x is not null then t1.anterior_communicating_artery \\\n    else 0 end as anterior_communicating_artery \\\n    , case when t2.coordinates_x is not null then t1.left_anterior_cerebral_artery \\\n    else 0 end as left_anterior_cerebral_artery \\\n    , case when t2.coordinates_x is not null then t1.right_anterior_cerebral_artery \\\n    else 0 end as right_anterior_cerebral_artery \\\n    , case when t2.coordinates_x is not null then t1.left_posterior_communicating_artery \\\n    else 0 end as left_posterior_communicating_artery \\\n    , case when t2.coordinates_x is not null then t1.right_posterior_communicating_artery \\\n    else 0 end as right_posterior_communicating_artery \\\n    , case when t2.coordinates_x is not null then t1.basilar_tip \\\n    else 0 end as basilar_tip \\\n    , case when t2.coordinates_x is not null then t1.other_posterior_circulation \\\n    else 0 end as other_posterior_circulation \\\n    from train_meta_data t1 \\\n    join df_all_coordinates t2 \\\n    on t1.SeriesInstanceUID = t2.folder_name\" \\\n).pl()\n\nprint(\"Full training data: \", df_all_data.shape)\nprint(\"Full training data columns: \", df_all_data.columns)\nprint(\"Aneurysm not present in {0} series\".format(df_all_data.filter(pl.col(\"coordinates_x\").is_null()).shape[0]))\n\nprint(\"Aneurysm present in {0} series\".format(df_all_data.filter(pl.col(\"coordinates_x\").is_not_null()).shape[0]))\n\nprint(\"Aneurysm not shown in {0} images\".format(df_all_data.filter(pl.col(\"aneurysm_present_in_image\")==0).shape[0]))\n\nprint(\"Aneurysm shown in {0} images\".format(df_all_data.filter(pl.col(\"aneurysm_present_in_image\")==1).shape[0]))\n\nprint(df_all_data.select([\"coordinates_x\", \"coordinates_y\"]).describe())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_all_data.write_parquet('full_training_data.parquet')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Looking at a specific CTA image that shows aneurysm\n## Taking a multi-frame image by converting it to single-frame image","metadata":{}},{"cell_type":"code","source":"df_all_data = pl.read_parquet('/kaggle/input/rsna-aneurysm-train-metadata-suman/full_training_data.parquet')\nprint(\"Shape of training metadata\", df_all_data.shape)\ndf_all_data.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:48:43.82027Z","iopub.execute_input":"2025-09-05T19:48:43.820589Z","iopub.status.idle":"2025-09-05T19:48:44.147877Z","shell.execute_reply.started":"2025-09-05T19:48:43.820563Z","shell.execute_reply":"2025-09-05T19:48:44.143024Z"}},"outputs":[{"name":"stdout","text":"Shape of training metadata (1001346, 24)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"['file_name',\n 'image_shape',\n 'coordinates_x',\n 'coordinates_y',\n 'coordinates_f',\n 'aneurysm_present_in_series',\n 'aneurysm_present_in_image',\n 'seriesinstanceuid',\n 'patientage',\n 'patientsex',\n 'modality',\n 'left_infraclinoid_internal_carotid_artery',\n 'right_infraclinoid_internal_carotid_artery',\n 'left_supraclinoid_internal_carotid_artery',\n 'right_supraclinoid_internal_carotid_artery',\n 'left_middle_cerebral_artery',\n 'right_middle_cerebral_artery',\n 'anterior_communicating_artery',\n 'left_anterior_cerebral_artery',\n 'right_anterior_cerebral_artery',\n 'left_posterior_communicating_artery',\n 'right_posterior_communicating_artery',\n 'basilar_tip',\n 'other_posterior_circulation']"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"root_folder = \"/kaggle/input/rsna-intracranial-aneurysm-detection/series\"\n\ndef create_full_image_path(row_data):\n    return row_data['root_folder'] + '/' + row_data['seriesinstanceuid'] + '/' + row_data['file_name']\n\ndf_all_data = df_all_data.with_columns(pl.lit(root_folder).alias(\"root_folder\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:48:47.132372Z","iopub.execute_input":"2025-09-05T19:48:47.132737Z","iopub.status.idle":"2025-09-05T19:48:47.157229Z","shell.execute_reply.started":"2025-09-05T19:48:47.132708Z","shell.execute_reply":"2025-09-05T19:48:47.151839Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df_all_data = df_all_data.with_columns([\n    pl.struct(pl.col(\"root_folder\"), pl.col(\"seriesinstanceuid\"), pl.col(\"file_name\"))\n    .map_elements(create_full_image_path, return_dtype=pl.String)\n    #.cast(pl.String)\n    .alias(\"full_image_path\")\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:48:51.664226Z","iopub.execute_input":"2025-09-05T19:48:51.664589Z","iopub.status.idle":"2025-09-05T19:48:55.905106Z","shell.execute_reply.started":"2025-09-05T19:48:51.66456Z","shell.execute_reply":"2025-09-05T19:48:55.900296Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df_all_data.filter(\n    (pl.col('coordinates_x').is_not_null())\n    &\n    (pl.col('coordinates_f') == 0)\n).head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_all_data.filter(\n    (pl.col('coordinates_x').is_not_null())\n    &\n    (pl.col('coordinates_f') != 0)\n).head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_all_data.filter(\n    (pl.col('coordinates_x').is_not_null())\n    &\n    (pl.col('coordinates_f') != 0)\n).select(pl.col('full_image_path')).count()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_single_frame(multiframe_path, slice_number, output_path=None):\n    \"\"\"\n    Extract a single frame from a multi-frame DICOM\n    \n    Args:\n        multiframe_path: Path to multi-frame DICOM file\n        slice_number: The slice number to extract (0-based index)\n        output_path: Path to save the single-frame DICOM. If None, returns the dataset\n    \"\"\"\n    try:\n        # Read the multi-frame DICOM with force=True to handle potentially corrupted files\n        multi_ds = dcmread(multiframe_path, force=True)\n        \n        # Verify it's a multi-frame image\n        if not hasattr(multi_ds, 'NumberOfFrames'):\n            raise ValueError(\"Input DICOM is not a multi-frame image\")\n        \n        # Check if slice number is valid\n        if slice_number >= multi_ds.NumberOfFrames:\n            raise ValueError(f\"Slice number {slice_number} is out of range. \"\n                           f\"Image has {multi_ds.NumberOfFrames} frames\")\n        \n        # Create new dataset for single frame\n        single_ds = FileDataset(output_path or \"temp.dcm\", {}, \n                              file_meta=FileMetaDataset(), \n                              preamble=b\"\\0\" * 128)\n        \n        # Copy attributes from multi-frame dataset\n        attrs_to_copy = allowed_tags\n        \n        for attr in attrs_to_copy:\n            if hasattr(multi_ds, attr):\n                setattr(single_ds, attr, getattr(multi_ds, attr))\n        \n        # Generate new UIDs\n        single_ds.SOPInstanceUID = generate_uid()\n        single_ds.file_meta.MediaStorageSOPInstanceUID = single_ds.SOPInstanceUID\n        \n        # Set transfer syntax to uncompressed little endian\n        single_ds.file_meta.TransferSyntaxUID = ImplicitVRLittleEndian\n        single_ds.file_meta.MediaStorageSOPClassUID = multi_ds.file_meta.MediaStorageSOPClassUID\n        if hasattr(multi_ds.file_meta, 'ImplementationClassUID'):\n            single_ds.file_meta.ImplementationClassUID = multi_ds.file_meta.ImplementationClassUID\n        \n        # Set instance-specific attributes\n        single_ds.InstanceNumber = slice_number + 1\n        \n        try:\n            # Try to get pixel array directly\n            pixel_array = multi_ds.pixel_array[slice_number]\n        except Exception as e:\n            print(f\"Warning: Could not directly access pixel_array: {e}\")\n            # Alternative approach: decompress and get pixels\n            if hasattr(multi_ds, 'decompress'):\n                multi_ds.decompress()\n            pixel_array = multi_ds.pixel_array[slice_number]\n        \n        # Set pixel data\n        single_ds.PixelData = pixel_array.tobytes()\n        \n        # Update image-specific attributes\n        single_ds.NumberOfFrames = 1\n        \n        # Try to copy position and orientation\n        try:\n            if hasattr(multi_ds, 'PerFrameFunctionalGroupsSequence'):\n                frame_content = multi_ds.PerFrameFunctionalGroupsSequence[slice_number]\n                \n                if hasattr(frame_content, 'PlanePositionSequence'):\n                    position = frame_content.PlanePositionSequence[0].ImagePositionPatient\n                    single_ds.ImagePositionPatient = position\n                \n                if hasattr(frame_content, 'PlaneOrientationSequence'):\n                    orientation = frame_content.PlaneOrientationSequence[0].ImageOrientationPatient\n                    single_ds.ImageOrientationPatient = orientation\n        except Exception as e:\n            print(f\"Warning: Could not copy position/orientation: {e}\")\n        \n        # Add creation timestamp\n        dt = datetime.datetime.now()\n        single_ds.ContentDate = dt.strftime('%Y%m%d')\n        single_ds.ContentTime = dt.strftime('%H%M%S.%f')\n        \n        # Save or return the dataset\n        if output_path:\n            single_ds.save_as(output_path, write_like_original=False)\n            return None\n        return single_ds\n    \n    except Exception as e:\n        print(f\"Error extracting frame: {e}\")\n        raise\n\n# Alternative version using different approach for compressed files\ndef extract_single_frame_alternative(multiframe_path, slice_number, output_path=None):\n    \"\"\"\n    Alternative version for handling problematic files\n    \"\"\"\n    try:\n        # Read with force and stop before pixels\n        multi_ds = dcmread(multiframe_path, force=True, stop_before_pixels=True)\n        \n        # Read pixel data separately\n        with open(multiframe_path, 'rb') as f:\n            multi_ds.PixelData = f.read()\n        \n        # Decompress if needed\n        if hasattr(multi_ds, 'decompress'):\n            multi_ds.decompress()\n        \n        # Get pixel array\n        pixel_array = multi_ds.pixel_array[slice_number]\n        \n        # Create new dataset\n        single_ds = FileDataset(output_path or \"temp.dcm\", {}, \n                              file_meta=FileMetaDataset(), \n                              preamble=b\"\\0\" * 128)\n        \n        # Copy attributes (same as before)\n        attrs_to_copy = allowed_tags\n        \n        for attr in attrs_to_copy:\n            if hasattr(multi_ds, attr):\n                setattr(single_ds, attr, getattr(multi_ds, attr))\n        \n        # Generate new UIDs\n        single_ds.SOPInstanceUID = generate_uid()\n        single_ds.file_meta.MediaStorageSOPInstanceUID = single_ds.SOPInstanceUID\n        \n        # Set transfer syntax to uncompressed little endian\n        single_ds.file_meta.TransferSyntaxUID = ImplicitVRLittleEndian\n        single_ds.file_meta.MediaStorageSOPClassUID = multi_ds.file_meta.MediaStorageSOPClassUID\n        if hasattr(multi_ds.file_meta, 'ImplementationClassUID'):\n            single_ds.file_meta.ImplementationClassUID = multi_ds.file_meta.ImplementationClassUID\n        \n        # Set instance-specific attributes\n        single_ds.InstanceNumber = slice_number + 1\n        \n        try:\n            # Try to get pixel array directly\n            pixel_array = multi_ds.pixel_array[slice_number]\n        except Exception as e:\n            print(f\"Warning: Could not directly access pixel_array: {e}\")\n            # Alternative approach: decompress and get pixels\n            if hasattr(multi_ds, 'decompress'):\n                multi_ds.decompress()\n            pixel_array = multi_ds.pixel_array[slice_number]\n        \n        # Set pixel data\n        single_ds.PixelData = pixel_array.tobytes()\n        \n        # Update image-specific attributes\n        single_ds.NumberOfFrames = 1\n        \n        # Try to copy position and orientation\n        try:\n            if hasattr(multi_ds, 'PerFrameFunctionalGroupsSequence'):\n                frame_content = multi_ds.PerFrameFunctionalGroupsSequence[slice_number]\n                \n                if hasattr(frame_content, 'PlanePositionSequence'):\n                    position = frame_content.PlanePositionSequence[0].ImagePositionPatient\n                    single_ds.ImagePositionPatient = position\n                \n                if hasattr(frame_content, 'PlaneOrientationSequence'):\n                    orientation = frame_content.PlaneOrientationSequence[0].ImageOrientationPatient\n                    single_ds.ImageOrientationPatient = orientation\n        except Exception as e:\n            print(f\"Warning: Could not copy position/orientation: {e}\")\n        \n        # Add creation timestamp\n        dt = datetime.datetime.now()\n        single_ds.ContentDate = dt.strftime('%Y%m%d')\n        single_ds.ContentTime = dt.strftime('%H%M%S.%f')\n        \n        # Save or return the dataset\n        if output_path:\n            single_ds.save_as(output_path, write_like_original=False)\n            return None\n        return single_ds\n        \n    except Exception as e:\n        print(f\"Error in alternative extraction: {e}\")\n        raise\n\n# Function to try both methods\ndef safe_extract_single_frame(multiframe_path, slice_number, output_path=None):\n    \"\"\"\n    Try both extraction methods\n    \"\"\"\n    try:\n        return extract_single_frame(multiframe_path, slice_number, output_path)\n    except Exception as e:\n        print(f\"Primary method failed: {e}\")\n        print(\"Trying alternative method...\")\n        try:\n            return extract_single_frame_alternative(multiframe_path, slice_number, output_path)\n        except Exception as e2:\n            print(f\"Alternative method also failed: {e2}\")\n            raise\n\n# Version with zoom functionality\ndef load_and_view_single_slice_with_zoom(dcm_path, x_coord, y_coord, f_coord=None, zoom_size=100):\n    \"\"\"\n    Load and display a single DICOM slice with crosshair and zoomed inset\n    \n    Args:\n        dcm_path: Path to the DICOM file\n        x_coord: x coordinate for the crosshair\n        y_coord: y coordinate for the crosshair\n        zoom_size: Size of the zoom window in pixels\n    \"\"\"\n    # Read DICOM file\n    if f_coord:\n        ds = safe_extract_single_frame(dcm_path, f_coord)\n    else:\n        ds = dcmread(dcm_path)\n    img = ds.pixel_array\n    \n    # Create figure and axes\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n    \n    # Main image with crosshair\n    ax1.imshow(img, cmap='gray')\n    ax1.axvline(x=x_coord, color='red', alpha=0.5)\n    ax1.axhline(y=y_coord, color='red', alpha=0.5)\n    ax1.plot(x_coord, y_coord, 'r+', markersize=10, markeredgewidth=2)\n    \n    # Zoomed region\n    x_start = int(max(0, x_coord - zoom_size/2))\n    x_end = int(min(img.shape[1], x_coord + zoom_size/2))\n    y_start = int(max(0, y_coord - zoom_size/2))\n    y_end = int(min(img.shape[0], y_coord + zoom_size/2))\n    \n    zoomed = img[y_start:y_end, x_start:x_end]\n    ax2.imshow(zoomed, cmap='gray')\n    \n    # Add crosshair to zoomed region\n    center_x = x_coord - x_start\n    center_y = y_coord - y_start\n    ax2.axvline(x=center_x, color='red', alpha=0.5)\n    ax2.axhline(y=center_y, color='red', alpha=0.5)\n    ax2.plot(center_x, center_y, 'r+', markersize=10, markeredgewidth=2)\n    \n    ax1.axis('off')\n    ax2.axis('off')\n    ax1.set_title('Full Image')\n    ax2.set_title('Zoomed Region')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:49:02.776255Z","iopub.execute_input":"2025-09-05T19:49:02.776639Z","iopub.status.idle":"2025-09-05T19:49:02.81035Z","shell.execute_reply.started":"2025-09-05T19:49:02.776609Z","shell.execute_reply":"2025-09-05T19:49:02.80325Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dcm_path = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10656705618563493995266564048457485210/1.2.826.0.1.3680043.8.498.42869495026349479137655237867466396964.dcm'\nx_coord = 297.728962\ny_coord = 209.570827\nf_coord = 65\nload_and_view_single_slice_with_zoom(dcm_path, x_coord, y_coord, f_coord)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dcm_path = '/kaggle/input/rsna-intracranial-aneurysm-detection/series/1.2.826.0.1.3680043.8.498.10602156717395509282545203380100998253/1.2.826.0.1.3680043.8.498.50109132199445951854133683565774892169.dcm'\nx_coord = 256.300637\ny_coord = 146.099363\nload_and_view_single_slice_with_zoom(dcm_path, x_coord, y_coord, f_coord)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if f_coord:\n    ds = safe_extract_single_frame(dcm_path, f_coord)\nelse:\n    ds = dcmread(dcm_path)\n\narr = ds.pixel_array.astype(np.float32)\n\n# Apply rescale if present\nslope = float(getattr(ds, \"RescaleSlope\", 1) or 1)\nintercept = float(getattr(ds, \"RescaleIntercept\", 0) or 0)\narr = arr * slope + intercept\n\n# Handle MONOCHROME1 (invert)\nif getattr(ds, \"PhotometricInterpretation\", \"\") == \"MONOCHROME1\":\n    arr = arr.max() - arr\n\nimage = tf.convert_to_tensor(arr)\n\nexpanded_image = tf.expand_dims(image, -1)\nm, M=tf.math.reduce_min(expanded_image), tf.math.reduce_max(expanded_image)\nexpanded_image = (tf.image.grayscale_to_rgb(expanded_image)-m)/(M-m)\nexpanded_image = tf.image.resize(expanded_image, (128,128))\nsqzd_image = tf.squeeze(expanded_image)\n\ntrain_img = tf.reshape(sqzd_image, shape=(128, 128, 3))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_np = train_img.numpy()\nplt.imshow(image_np)\nplt.title(\"TensorFlow Image Visualization\")\nplt.axis('off') # Hide axes for cleaner image display\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_and_parse_dicom_files_tensorflow_train(dcm_path, f_coord):\n    if f_coord:\n        ds = safe_extract_single_frame(dcm_path, f_coord)\n    else:\n        ds = dcmread(dcm_path)\n    \n    arr = ds.pixel_array.astype(np.float32)\n    \n    # Apply rescale if present\n    slope = float(getattr(ds, \"RescaleSlope\", 1) or 1)\n    intercept = float(getattr(ds, \"RescaleIntercept\", 0) or 0)\n    arr = arr * slope + intercept\n    \n    # Handle MONOCHROME1 (invert)\n    if getattr(ds, \"PhotometricInterpretation\", \"\") == \"MONOCHROME1\":\n        arr = arr.max() - arr\n    \n    image = tf.convert_to_tensor(arr)\n    \n    expanded_image = tf.expand_dims(image, -1)\n    m, M=tf.math.reduce_min(expanded_image), tf.math.reduce_max(expanded_image)\n    expanded_image = (tf.image.grayscale_to_rgb(expanded_image)-m)/(M-m)\n    expanded_image = tf.image.resize(expanded_image, (128,128))\n    sqzd_image = tf.squeeze(expanded_image)\n\n    return sqzd_image\n\ndef preprocessing(dcm_path, f_coord):\n    train_img = read_and_parse_dicom_files_tensorflow_train(dcm_path, f_coord)\n    train_img = tf.reshape(train_img, shape=(128, 128, 3))\n    return train_img\n\ndef load_dataset_tensorflow_train(dcm_path, f_coord, labels):\n    image = preprocessing(dcm_path, f_coord)\n    return {\"images\": tf.cast(image, tf.float32), \"labels\": tf.cast(labels, tf.float32)}\n\ndef dict_to_tuple(inputs):\n    return inputs[\"images\"], inputs[\"labels\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:49:13.970529Z","iopub.execute_input":"2025-09-05T19:49:13.970888Z","iopub.status.idle":"2025-09-05T19:49:13.985601Z","shell.execute_reply.started":"2025-09-05T19:49:13.970859Z","shell.execute_reply":"2025-09-05T19:49:13.980772Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df_all_data.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:49:18.216715Z","iopub.execute_input":"2025-09-05T19:49:18.21707Z","iopub.status.idle":"2025-09-05T19:49:18.231618Z","shell.execute_reply.started":"2025-09-05T19:49:18.217042Z","shell.execute_reply":"2025-09-05T19:49:18.22668Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['file_name',\n 'image_shape',\n 'coordinates_x',\n 'coordinates_y',\n 'coordinates_f',\n 'aneurysm_present_in_series',\n 'aneurysm_present_in_image',\n 'seriesinstanceuid',\n 'patientage',\n 'patientsex',\n 'modality',\n 'left_infraclinoid_internal_carotid_artery',\n 'right_infraclinoid_internal_carotid_artery',\n 'left_supraclinoid_internal_carotid_artery',\n 'right_supraclinoid_internal_carotid_artery',\n 'left_middle_cerebral_artery',\n 'right_middle_cerebral_artery',\n 'anterior_communicating_artery',\n 'left_anterior_cerebral_artery',\n 'right_anterior_cerebral_artery',\n 'left_posterior_communicating_artery',\n 'right_posterior_communicating_artery',\n 'basilar_tip',\n 'other_posterior_circulation',\n 'root_folder',\n 'full_image_path']"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"cols_to_select = ['full_image_path', 'left_infraclinoid_internal_carotid_artery',  'right_infraclinoid_internal_carotid_artery',  'left_supraclinoid_internal_carotid_artery'\n                  ,  'right_supraclinoid_internal_carotid_artery',  'left_middle_cerebral_artery',  'right_middle_cerebral_artery',  'anterior_communicating_artery'\n                  ,  'left_anterior_cerebral_artery',  'right_anterior_cerebral_artery',  'left_posterior_communicating_artery',  'right_posterior_communicating_artery'\n                  ,  'basilar_tip',  'other_posterior_circulation'\n]\n\ndf_for_train_baseline = df_all_data.select(cols_to_select)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:49:21.465827Z","iopub.execute_input":"2025-09-05T19:49:21.466187Z","iopub.status.idle":"2025-09-05T19:49:21.477204Z","shell.execute_reply.started":"2025-09-05T19:49:21.46616Z","shell.execute_reply":"2025-09-05T19:49:21.472958Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"x_train, x_test_val = train_test_split(df_for_train_baseline, test_size=0.4, random_state=42)\nx_test, x_valid = train_test_split(x_test_val, test_size=0.2, random_state=42)\n\nprint(\"Training data shape : {0}\".format(x_train.shape))\nprint(\"Test data shape : {0}\".format(x_test.shape))\nprint(\"Validation data shape : {0}\".format(x_valid.shape))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:49:23.358092Z","iopub.execute_input":"2025-09-05T19:49:23.358489Z","iopub.status.idle":"2025-09-05T19:49:23.65388Z","shell.execute_reply.started":"2025-09-05T19:49:23.358458Z","shell.execute_reply":"2025-09-05T19:49:23.648735Z"}},"outputs":[{"name":"stdout","text":"Training data shape : (600807, 14)\nTest data shape : (320431, 14)\nValidation data shape : (80108, 14)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"label_cols = ['left_infraclinoid_internal_carotid_artery',  'right_infraclinoid_internal_carotid_artery',  'left_supraclinoid_internal_carotid_artery'\n                  ,  'right_supraclinoid_internal_carotid_artery',  'left_middle_cerebral_artery',  'right_middle_cerebral_artery',  'anterior_communicating_artery'\n                  ,  'left_anterior_cerebral_artery',  'right_anterior_cerebral_artery',  'left_posterior_communicating_artery',  'right_posterior_communicating_artery'\n                  ,  'basilar_tip',  'other_posterior_circulation'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:49:25.932243Z","iopub.execute_input":"2025-09-05T19:49:25.932608Z","iopub.status.idle":"2025-09-05T19:49:25.942322Z","shell.execute_reply.started":"2025-09-05T19:49:25.93258Z","shell.execute_reply":"2025-09-05T19:49:25.937876Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"#### This is a multi-label classification problem where each instance (i.e. each DICOM image) can be labelled with at-most 13 labels (i.e. brain locations).\n#### The resulting predictions will then need to be aggregated up at the level of each scan series\n#### Finally the main target variable has to be calculated as the max of all the 13 labels, i.e. if at least one of the 13 labels is 1 then the final target variable is 1","metadata":{}},{"cell_type":"code","source":"tpu_strategy.num_replicas_in_sync","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:49:27.919409Z","iopub.execute_input":"2025-09-05T19:49:27.919792Z","iopub.status.idle":"2025-09-05T19:49:27.935946Z","shell.execute_reply.started":"2025-09-05T19:49:27.919763Z","shell.execute_reply":"2025-09-05T19:49:27.929964Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"8"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"def generate_tf_datasets(p_df, p_BATCH_SIZE_PER_REPLICA):\n\n    BATCH_SIZE = p_BATCH_SIZE_PER_REPLICA * tpu_strategy.num_replicas_in_sync\n    \n    image_filenames = pl.Series(p_df.select(pl.col('full_image_path'))).to_list()\n    image_labels = pl.Series(p_df.select(label_cols)).to_list()\n    \n    image_dataset = tf.data.Dataset.from_tensor_slices((image_filenames, image_labels))\n    \n    image_ds = image_dataset.map(load_dataset_tensorflow_train, num_parallel_calls=tf.data.AUTOTUNE)\n    image_ds = image_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n    image_ds = image_ds.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n    image_ds = image_ds.prefetch(tf.data.AUTOTUNE)\n    \n    return image_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:51:32.561Z","iopub.execute_input":"2025-09-05T19:51:32.561391Z","iopub.status.idle":"2025-09-05T19:51:32.57148Z","shell.execute_reply.started":"2025-09-05T19:51:32.56136Z","shell.execute_reply":"2025-09-05T19:51:32.567978Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"train_ds = generate_tf_datasets(p_df=x_train, p_BATCH_SIZE_PER_REPLICA = 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:52:14.827707Z","iopub.execute_input":"2025-09-05T19:52:14.828181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(train_ds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}